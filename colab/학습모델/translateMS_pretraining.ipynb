{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "translateMS_pretraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGaxNphgT7wE",
        "outputId": "4fa36860-bbf9-4869-f87a-556679f4fc60"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep  6 01:34:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz6S58tZgmmj"
      },
      "source": [
        "# **Basic transformer Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE7YdsSoyDkJ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def get_angles(position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    #tf.newaxis : expand dimensions\n",
        "    angle_rads = get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # list[<start>:<end>:<step>] even indices '0::2'\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # list[<start>:<end>:<step>] even indices '1::2'\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    angle_rads = np.zeros(angle_rads.shape)\n",
        "    angle_rads[:, 0::2] = sines\n",
        "    angle_rads[:, 1::2] = cosines\n",
        "    pos_encoding = tf.constant(angle_rads)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return look_ahead_mask\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead)\n",
        "    but it must be broadcastable for addition.\n",
        "    Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    Returns:\n",
        "    output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, self.d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               target_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
        "\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, dropout_rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights\n",
        "\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size,target_vocab_size,\n",
        "               positional_encoding_input,positional_encoding_target,\n",
        "               dropout_rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                             input_vocab_size,positional_encoding_input, dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, positional_encoding_target, dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, input, target, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(input, training, enc_padding_mask)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        target, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return enc_output, dec_output, final_output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0_ixcb2gzCp"
      },
      "source": [
        "## How to schedule learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6bcWbF8yFN5"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaRXFVe0hHf4"
      },
      "source": [
        "# **Pre-training for theoretical data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRVBsC9JyTIZ",
        "outputId": "1d47b44a-1d63-49c5-d1d0-b33892ed1580"
      },
      "source": [
        "import time\n",
        "\n",
        "feature_description = {\n",
        "            'sequence': tf.io.VarLenFeature(tf.int64),\n",
        "            'mz': tf.io.VarLenFeature(tf.int64),\n",
        "            }\n",
        "\n",
        "def parse_function(example_proto):\n",
        "    parsed_example = tf.io.parse_single_example(example_proto,feature_description)\n",
        "    mz = parsed_example['mz'].values\n",
        "    sequence = parsed_example['sequence'].values\n",
        "    return mz, sequence\n",
        "\n",
        "path_train_data='/content/drive/MyDrive/translateMS/data/theoretical_preprocessed_train_data.tfrecords'\n",
        "path_valid_data='/content/drive/MyDrive/translateMS/data/theoretical_preprocessed_valid_data.tfrecords'\n",
        "\n",
        "#size_train_dataset = 990000\n",
        "train_dataset = tf.data.TFRecordDataset(path_train_data)#.take(size_train_dataset)\n",
        "valid_dataset = tf.data.TFRecordDataset(path_valid_data).map(parse_function)\n",
        "\n",
        "#Set batchs\n",
        "theoretical_data_size = 7448762\n",
        "BATCH_SIZE = 150\n",
        "NUM_BATCHS = int(int(theoretical_data_size*0.99)/BATCH_SIZE)\n",
        "train_batches = (train_dataset\n",
        "                 .map(parse_function)\n",
        "                 .padded_batch(BATCH_SIZE)\n",
        "                 .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "\n",
        "def create_masks(input, target):\n",
        "    # Encoder padding mask\n",
        "    enc_padding_mask = create_padding_mask(input)\n",
        "    # Used in the 2nd attention block in the decoder.\n",
        "    # This padding mask is used to mask the encoder outputs.\n",
        "    dec_padding_mask = create_padding_mask(input)\n",
        "    # Used in the 1st attention block in the decoder.\n",
        "    # It is used to pad and mask future tokens in the input received by\n",
        "    # the decoder.\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(target)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(target)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
        "\n",
        "\n",
        "'''\n",
        "d_model : input(embedding), ouput 차원\n",
        "num_layers : 인코더, 디코더 층\n",
        "num_heads : 멀티헤드 수\n",
        "d_ff : feedforward 차원 \n",
        "'''\n",
        "D_MODEL = 128\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 8\n",
        "DFF = 512\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "transformer = Transformer(\n",
        "    num_layers=NUM_LAYERS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dff=DFF,\n",
        "    input_vocab_size=600000,\n",
        "    target_vocab_size=30,\n",
        "    positional_encoding_input = 2000,\n",
        "    positional_encoding_target = 50,\n",
        "    dropout_rate=DROPOUT_RATE)\n",
        "\n",
        "#save checkpoint\n",
        "checkpoint_path = \"/content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)\n",
        "\n",
        "#ckpt_num = '/content/drive/MyDrive/translateMS/checkpoints/train/ckpt-12'\n",
        "#ckpt.restore(ckpt_num)\n",
        "#print('Checkpoint restored!!')\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print('Latest checkpoint restored!!')\n",
        "\n",
        "train_step_signature = [\n",
        "  tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "  tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(input, target):\n",
        "\n",
        "    target_input = target[:, :-1]\n",
        "    target_real = target[:, 1:]\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input, target_input)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        _, _, predictions, _ = transformer(input, target_input,\n",
        "                                   True,\n",
        "                                   enc_padding_mask,\n",
        "                                   combined_mask,\n",
        "                                   dec_padding_mask)\n",
        "\n",
        "        loss = loss_function(target_real, predictions)\n",
        "\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy_function(target_real, predictions))\n",
        "\n",
        "\n",
        "def evaluate_aminoacid_level(dataset):\n",
        "    batch_size = 64\n",
        "    num_batchs = 0\n",
        "    accuracy = 0\n",
        "    loss = 0\n",
        "    dataset_batchs = dataset.padded_batch(batch_size = batch_size, drop_remainder=True)\n",
        "\n",
        "    for batch, (input, target) in enumerate(dataset_batchs):\n",
        "        num_batchs = batch+1\n",
        "\n",
        "        target_input = target[:, :-1]\n",
        "        target_real = target[:, 1:]\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input, target_input)\n",
        "\n",
        "        _, _, predictions, _ = transformer(input, target_input,\n",
        "                                   False,\n",
        "                                   enc_padding_mask,\n",
        "                                   combined_mask,\n",
        "                                   dec_padding_mask)\n",
        "        loss += loss_function(target_real, predictions)\n",
        "        accuracy += accuracy_function(target_real, predictions)\n",
        "\n",
        "    return loss/num_batchs, accuracy/num_batchs\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest checkpoint restored!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j3NJ966eOef",
        "outputId": "96bbf021-82ab-4593-df33-f304187359b3"
      },
      "source": [
        "print(ckpt_manager.latest_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p15R0rQxqYDu",
        "outputId": "e450ad4f-0ab7-49ff-9726-3f7256156d49"
      },
      "source": [
        "for mz, seq in valid_dataset:\n",
        "  print(mz,seq)\n",
        "  break  \n",
        "\n",
        "\n",
        "for batch, (input, target) in enumerate(train_batches):\n",
        "  print(input, target)\n",
        "  break  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[     1  11105  11203  12906  15710  15809  17511  21012  21110  22813\n",
            "  28615  28713  30416  32320  32419  34121  39923  40021  41724  43629\n",
            "  43727  45430  52827  52926  54628  54937  55035  56738  62932  63030\n",
            "  64733  68643  68741  70444  76638  76736  78439  78748  78846  80549\n",
            "  87946  88045  89747  91652  91750  93453  99255  99353 101056 102960\n",
            " 103059 104761 110563 110662 112364 115865 115963 117666 120470 120568\n",
            " 122271 134976      2], shape=(63,), dtype=int64) tf.Tensor([ 1 15  5  8  8  8 21 16  7  8  7 18  2], shape=(13,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[    1  2051  2100 ...     0     0     0]\n",
            " [    1  1868  1901 ...     0     0     0]\n",
            " [    1  3269  3302 ...     0     0     0]\n",
            " ...\n",
            " [    1  4854  4903 ...     0     0     0]\n",
            " [    1  6553  6602 ...     0     0     0]\n",
            " [    1 13909 14008 ...     0     0     0]], shape=(150, 669), dtype=int64) tf.Tensor(\n",
            "[[ 1 19 11 ...  0  0  0]\n",
            " [ 1 13  8 ...  0  0  0]\n",
            " [ 1  8  7 ...  0  0  0]\n",
            " ...\n",
            " [ 1  8 15 ...  0  0  0]\n",
            " [ 1 11 19 ...  0  0  0]\n",
            " [ 1 18 14 ...  0  0  0]], shape=(150, 40), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "mI5hQBa39mwb",
        "outputId": "59888971-9296-4b6c-b7fb-c8d29d23e4fb"
      },
      "source": [
        "epoch = 0\n",
        "#for epoch in range(EPOCHS):\n",
        "while True:\n",
        "    start = time.time()\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "\n",
        "    for batch, (input, target) in enumerate(train_batches):\n",
        "        train_step(input, target)\n",
        "        print('\\r',f'Epoch {epoch + 1} | batch {batch+1}/{NUM_BATCHS} Loss {train_loss.result():.3f} Accuracy {train_accuracy.result():.4f}',end='')\n",
        "\n",
        "    print('\\r',f'Epoch {epoch + 1} : Time {time.time() - start:.2f}s')\n",
        "\n",
        "    print(f'\\tTrain | Loss {train_loss.result():.3f}, Accuracy {train_accuracy.result():.3f}')\n",
        "\n",
        "    valid_loss, valid_accuracy = evaluate_aminoacid_level(valid_dataset)\n",
        "    print(f'\\tValid | Loss {valid_loss:.3f}, Accuracy {valid_accuracy:.3f}')\n",
        "\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
        " \n",
        "    epoch+=1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch 1 : Time 12028.05s\n",
            "\tTrain | Loss 0.017, Accuracy 0.995\n",
            "\tValid | Loss 0.004, Accuracy 0.999\n",
            "Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-15\n",
            " Epoch 2 : Time 11972.85s\n",
            "\tTrain | Loss 0.016, Accuracy 0.995\n",
            "\tValid | Loss 0.003, Accuracy 0.999\n",
            "Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-16\n",
            " Epoch 3 | batch 316/49161 Loss 0.016 Accuracy 0.9949"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-90de1ec67267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'Epoch {epoch + 1} | batch {batch+1}/{NUM_BATCHS} Loss {train_loss.result():.3f} Accuracy {train_accuracy.result():.4f}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDA6VOVc8_47"
      },
      "source": [
        "\n",
        "def evaluate_aminoacid_level(dataset):\n",
        "    batch_size = 64\n",
        "    num_batchs = 0\n",
        "    accuracy = 0\n",
        "    loss = 0\n",
        "    dataset_batchs = dataset.padded_batch(batch_size = batch_size, drop_remainder=True)\n",
        "\n",
        "    for batch, (input, target) in enumerate(dataset_batchs):\n",
        "        num_batchs = batch+1\n",
        "\n",
        "        target_input = target[:, :-1]\n",
        "        target_real = target[:, 1:]\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input, target_input)\n",
        "\n",
        "        _, _, predictions, _ = transformer(input, target_input,\n",
        "                                   False,\n",
        "                                   enc_padding_mask,\n",
        "                                   combined_mask,\n",
        "                                   dec_padding_mask)\n",
        "        loss += loss_function(target_real, predictions)\n",
        "        accuracy += accuracy_function(target_real, predictions)\n",
        "\n",
        "    return loss/num_batchs, accuracy/num_batchs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlXJ7zZk85V3",
        "outputId": "05ba2400-6cb1-41ac-d794-d610e5c331d9"
      },
      "source": [
        "  valid_loss, valid_accuracy = evaluate_aminoacid_level(valid_dataset)\n",
        "  print(f'\\tValid | Loss {valid_loss:.3f}, Accuracy {valid_accuracy:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tValid | Loss 0.022, Accuracy 0.993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D1mIWpEVI_3"
      },
      "source": [
        "##Info. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "I4PDaAARRWAw",
        "outputId": "8a7333b2-ef5b-42e3-afe2-b091d1cba747"
      },
      "source": [
        "'''\n",
        "D_MODEL = 128\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 8\n",
        "DFF = 512\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "\n",
        " Epoch 1 : Time 2700.33s\n",
        "\tTrain | Loss  0.432, Accuracy 0.843\n",
        "\tValid | Loss 0.057, Accuracy 0.982\n",
        "Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-1\n",
        " Epoch 2 : Time 2700.33s\n",
        "\tTrain | Loss 0.243, Accuracy 0.951\n",
        "\tValid | Loss 0.022, Accuracy 0.993\n",
        "Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-2\n",
        " Epoch 1 : Time 24998.77s\n",
        "\tTrain | Loss 0.056, Accuracy 0.982\n",
        "\tValid | Loss 0.013, Accuracy 0.996\n",
        "Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-3\n",
        " Epoch 2 : Time 24959.29s\n",
        "\tTrain | Loss 0.043, Accuracy 0.986\n",
        "\tValid | Loss 0.011, Accuracy 0.996\n",
        "Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-4\n",
        " Epoch 1 : Time 24926.82s\n",
        "\tTrain | Loss 0.036, Accuracy 0.989\n",
        "\tValid | Loss 0.009, Accuracy 0.997\n",
        "Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-5\n",
        " Epoch 2 : Time 24905.39s\n",
        "\tTrain | Loss 0.031, Accuracy 0.990\n",
        "\tValid | Loss 0.010, Accuracy 0.997\n",
        "Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-6\n",
        " Epoch 1 : Time 12009.18s\n",
        "\tTrain | Loss 0.028, Accuracy 0.991\n",
        "\tValid | Loss 0.007, Accuracy 0.998\n",
        "Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-7\n",
        " Epoch 2 : Time 11995.47s\n",
        "\tTrain | Loss 0.025, Accuracy 0.992\n",
        "\tValid | Loss 0.007, Accuracy 0.998\n",
        "Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-8\n",
        " Epoch 3 : Time 11983.60s\n",
        "\tTrain | Loss 0.023, Accuracy 0.993\n",
        "\tValid | Loss 0.006, Accuracy 0.998\n",
        "Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-9\n",
        " Epoch 4 : Time 11986.56s\n",
        "\tTrain | Loss 0.022, Accuracy 0.993\n",
        "\tValid | Loss 0.005, Accuracy 0.998\n",
        "Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-10\n",
        " Epoch 5 : Time 11984.53s\n",
        "\tTrain | Loss 0.021, Accuracy 0.993\n",
        "\tValid | Loss 0.004, Accuracy 0.999\n",
        "Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-11\n",
        " Epoch 6 : Time 11969.97s\n",
        "\tTrain | Loss 0.019, Accuracy 0.994\n",
        "\tValid | Loss 0.005, Accuracy 0.999\n",
        "Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-12\n",
        " Epoch 1 : Time 11993.11s\n",
        "\tTrain | Loss 0.018, Accuracy 0.994\n",
        "\tValid | Loss 0.004, Accuracy 0.999\n",
        "Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-13\n",
        " Epoch 2 : Time 11965.59s\n",
        "\tTrain | Loss 0.018, Accuracy 0.994\n",
        "\tValid | Loss 0.004, Accuracy 0.999\n",
        "Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-14\n",
        "Epoch 1 : Time 12028.05s\n",
        "\tTrain | Loss 0.017, Accuracy 0.995\n",
        "\tValid | Loss 0.004, Accuracy 0.999\n",
        "Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-15\n",
        " Epoch 2 : Time 11972.85s\n",
        "\tTrain | Loss 0.016, Accuracy 0.995\n",
        "\tValid | Loss 0.003, Accuracy 0.999\n",
        "Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-16\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "D_MODEL = 64\n",
        "NUM_LAYERS = 1\n",
        "NUM_HEADS = 1\n",
        "DFF = 128\n",
        "DROPOUT_RATE = 0.2\n",
        " Epoch 1 : Time 2700.33s\n",
        "\tTrain | Loss 1.763, Accuracy 0.457\n",
        "\tValid | Loss 1.354, Accuracy 0.572\n",
        "Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-1\n",
        " Epoch 2 : Time 2688.46s\n",
        "\tTrain | Loss 1.496, Accuracy 0.532\n",
        "\tValid | Loss 1.235, Accuracy 0.612\n",
        "Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-2\n",
        " Epoch 3 : Time 2700.66s\n",
        "\tTrain | Loss 1.434, Accuracy 0.551\n",
        "\tValid | Loss 1.166, Accuracy 0.634\n",
        "Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-3\n",
        " Epoch 4 : Time 2706.47s\n",
        "\tTrain | Loss 1.398, Accuracy 0.562\n",
        "\tValid | Loss 1.110, Accuracy 0.650\n",
        "Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-4\n",
        " Epoch 5 : Time 2702.19s\n",
        "\tTrain | Loss 1.371, Accuracy 0.571\n",
        "\tValid | Loss 1.080, Accuracy 0.661\n",
        "Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-5\n",
        " Epoch 6 : Time 2700.80s\n",
        "\tTrain | Loss 1.349, Accuracy 0.578\n",
        "\tValid | Loss 1.054, Accuracy 0.670\n",
        "Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-6\n",
        " Epoch 7 : Time 2701.57s\n",
        "\tTrain | Loss 1.328, Accuracy 0.585\n",
        "\tValid | Loss 1.006, Accuracy 0.685\n",
        "Saving checkpoint for epoch 7 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-7\n",
        " Epoch 8 : Time 2701.76s\n",
        "\tTrain | Loss 1.307, Accuracy 0.592\n",
        "\tValid | Loss 0.978, Accuracy 0.695\n",
        "Saving checkpoint for epoch 8 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-8\n",
        " Epoch 9 : Time 2710.60s\n",
        "\tTrain | Loss 1.284, Accuracy 0.600\n",
        "\tValid | Loss 0.941, Accuracy 0.707\n",
        "Saving checkpoint for epoch 9 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-9\n",
        " Epoch 10 : Time 2705.58s\n",
        "\tTrain | Loss 1.259, Accuracy 0.608\n",
        "\tValid | Loss 0.907, Accuracy 0.717\n",
        "Saving checkpoint for epoch 10 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-10\n",
        " Epoch 11 : Time 2701.31s\n",
        "\tTrain | Loss 1.234, Accuracy 0.616\n",
        "\tValid | Loss 0.872, Accuracy 0.728\n",
        "Saving checkpoint for epoch 11 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-11\n",
        " Epoch 12 : Time 2700.67s\n",
        "\tTrain | Loss 1.210, Accuracy 0.624\n",
        "\tValid | Loss 0.851, Accuracy 0.735\n",
        "Saving checkpoint for epoch 12 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-12\n",
        " Epoch 13 : Time 2701.21s\n",
        "\tTrain | Loss 1.187, Accuracy 0.632\n",
        "\tValid | Loss 0.818, Accuracy 0.745\n",
        "Saving checkpoint for epoch 13 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-13\n",
        " Epoch 14 : Time 2701.20s\n",
        "\tTrain | Loss 1.166, Accuracy 0.639\n",
        "\tValid | Loss 0.787, Accuracy 0.755\n",
        "Saving checkpoint for epoch 14 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-14\n",
        " Epoch 15 : Time 2701.08s\n",
        "\tTrain | Loss 1.146, Accuracy 0.645\n",
        "\tValid | Loss 0.762, Accuracy 0.762\n",
        "Saving checkpoint for epoch 15 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-15\n",
        " Epoch 16 : Time 2701.46s\n",
        "\tTrain | Loss 1.129, Accuracy 0.651\n",
        "\tValid | Loss 0.742, Accuracy 0.768\n",
        "Saving checkpoint for epoch 16 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-16\n",
        " Epoch 17 : Time 2703.07s\n",
        "\tTrain | Loss 1.112, Accuracy 0.656\n",
        "\tValid | Loss 0.722, Accuracy 0.775\n",
        "Saving checkpoint for epoch 17 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-17\n",
        " Epoch 18 : Time 2701.19s\n",
        "\tTrain | Loss 1.098, Accuracy 0.661\n",
        "\tValid | Loss 0.710, Accuracy 0.779\n",
        "Saving checkpoint for epoch 18 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-18\n",
        " Epoch 19 : Time 2700.99s\n",
        "\tTrain | Loss 1.084, Accuracy 0.665\n",
        "\tValid | Loss 0.700, Accuracy 0.783\n",
        "Saving checkpoint for epoch 19 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-19\n",
        " Epoch 20 : Time 2703.05s\n",
        "\tTrain | Loss 1.072, Accuracy 0.669\n",
        "\tValid | Loss 0.688, Accuracy 0.786\n",
        "Saving checkpoint for epoch 20 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-20\n",
        " Epoch 21 : Time 2706.26s\n",
        "\tTrain | Loss 1.061, Accuracy 0.673\n",
        "\tValid | Loss 0.675, Accuracy 0.789\n",
        "Saving checkpoint for epoch 21 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-21\n",
        " Epoch 22 : Time 2710.75s\n",
        "\tTrain | Loss 1.051, Accuracy 0.676\n",
        "\tValid | Loss 0.666, Accuracy 0.792\n",
        "Saving checkpoint for epoch 22 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-22\n",
        " Epoch 23 : Time 2709.67s\n",
        "\tTrain | Loss 1.042, Accuracy 0.679\n",
        "\tValid | Loss 0.660, Accuracy 0.794\n",
        "Saving checkpoint for epoch 23 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-23\n",
        " Epoch 24 : Time 2704.67s\n",
        "\tTrain | Loss 1.034, Accuracy 0.682\n",
        "\tValid | Loss 0.650, Accuracy 0.797\n",
        "Saving checkpoint for epoch 24 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-24\n",
        " Epoch 25 : Time 2706.52s\n",
        "\tTrain | Loss 1.027, Accuracy 0.684\n",
        "\tValid | Loss 0.640, Accuracy 0.800\n",
        "Saving checkpoint for epoch 25 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-25\n",
        " Epoch 26 : Time 2706.80s\n",
        "\tTrain | Loss 1.020, Accuracy 0.686\n",
        "\tValid | Loss 0.628, Accuracy 0.805\n",
        "Saving checkpoint for epoch 26 at /content/drive/MyDrive/translateMS/checkpoints/pretraining_64_1_1_128_0.2/ckpt-26\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "D_MODEL = 64\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 2\n",
        "DFF = 128\n",
        "DROPOUT_RATE = 0.5\n",
        "\n",
        "  Epoch 1 : Time 11854.26s\n",
        "\tTrain | Loss 1.910, Accuracy 0.418\n",
        "\tValid | Loss 1.532, Accuracy 0.548\n",
        "Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-1\n",
        " Epoch 2 : Time 11864.57s\n",
        "\tTrain | Loss 1.576, Accuracy 0.515\n",
        "\tValid | Loss 1.398, Accuracy 0.580\n",
        "Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-2\n",
        " Epoch 3 : Time 11875.01s\n",
        "\tTrain | Loss 1.516, Accuracy 0.534\n",
        "\tValid | Loss 1.325, Accuracy 0.601\n",
        "Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-3\n",
        " Epoch 4 : Time 11860.26s\n",
        "\tTrain | Loss 1.478, Accuracy 0.546\n",
        "\tValid | Loss 1.279, Accuracy 0.615\n",
        "Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-4\n",
        " Epoch 5 : Time 11867.08s\n",
        "\tTrain | Loss 1.450, Accuracy 0.555\n",
        "\tValid | Loss 1.277, Accuracy 0.618\n",
        "Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-5\n",
        " Epoch 6 : Time 11867.80s\n",
        "\tTrain | Loss 1.427, Accuracy 0.562\n",
        "\tValid | Loss 1.301, Accuracy 0.619\n",
        "Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-6\n",
        " Epoch 7 | batch 829/14402 Loss 1.419 Accuracy 0.5650\n",
        "  Epoch 1 : Time 7642.94s\n",
        "\tTrain | Loss 1.409, Accuracy 0.568\n",
        "\tValid | Loss 1.334, Accuracy 0.613\n",
        "Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-7\n",
        " Epoch 2 : Time 7627.85s\n",
        "\tTrain | Loss 1.394, Accuracy 0.573\n",
        "\tValid | Loss 1.375, Accuracy 0.608\n",
        "Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-8\n",
        " Epoch 3 : Time 7619.00s\n",
        "\tTrain | Loss 1.381, Accuracy 0.578\n",
        "\tValid | Loss 1.405, Accuracy 0.606\n",
        "Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-9\n",
        " Epoch 4 : Time 7617.24s\n",
        "\tTrain | Loss 1.369, Accuracy 0.581\n",
        "\tValid | Loss 1.473, Accuracy 0.595\n",
        "Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-10\n",
        " Epoch 5 : Time 7616.66s\n",
        "\tTrain | Loss 1.360, Accuracy 0.585\n",
        "\tValid | Loss 1.527, Accuracy 0.588\n",
        "Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-11\n",
        " Epoch 6 : Time 7614.13s\n",
        "\tTrain | Loss 1.351, Accuracy 0.588\n",
        "\tValid | Loss 1.566, Accuracy 0.586\n",
        "Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-12\n",
        " Epoch 7 : Time 7619.38s\n",
        "\tTrain | Loss 1.342, Accuracy 0.591\n",
        "\tValid | Loss 1.621, Accuracy 0.580\n",
        "Saving checkpoint for epoch 7 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-13\n",
        " Epoch 8 : Time 7608.90s\n",
        "\tTrain | Loss 1.335, Accuracy 0.593\n",
        "\tValid | Loss 1.589, Accuracy 0.589\n",
        "Saving checkpoint for epoch 8 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-14\n",
        " Epoch 9 : Time 7607.37s\n",
        "\tTrain | Loss 1.327, Accuracy 0.596\n",
        "\tValid | Loss 1.683, Accuracy 0.577\n",
        "Saving checkpoint for epoch 9 at /content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-15\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-40bef8539531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_accuracy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m '''\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loss_list' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1zjZ0mQxT_Y"
      },
      "source": [
        "## Evaluate test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWqgsNyyxJpC"
      },
      "source": [
        "def evaluate_peptide_level(dataset, max_length = 50):\n",
        "    cnt_total =0\n",
        "    cnt_correct = 0\n",
        "    for mz, sequence in dataset:\n",
        "        cnt_total+=1\n",
        "        if(cnt_total%10 == 0):\n",
        "            print(cnt_total, cnt_correct/(cnt_total-1))\n",
        "\n",
        "        encoder_input = tf.convert_to_tensor([mz])\n",
        "        start, end = 1,2\n",
        "        output = tf.convert_to_tensor([start],dtype=tf.int64)\n",
        "        output = tf.expand_dims(output, 0)\n",
        "\n",
        "        for i in range(max_length):\n",
        "            enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "                encoder_input, output)\n",
        "            # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "            _, _, predictions, _ = transformer(encoder_input, output,\n",
        "                                   False,\n",
        "                                   enc_padding_mask,\n",
        "                                   combined_mask,\n",
        "                                   dec_padding_mask)\n",
        "             \n",
        "            # select the last word from the seq_len dimension\n",
        "            predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "            predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "            # concatentate the predicted_id to the output which is given to the decoder\n",
        "            # as its input.\n",
        "            output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "            # return the result if the predicted_id is equal to the end token\n",
        "            if predicted_id == end:\n",
        "                if output.shape[1]==sequence.shape[0] and tf.reduce_all(output[0] == sequence):\n",
        "                    cnt_correct+=1\n",
        "                break\n",
        "\n",
        "    return cnt_correct/cnt_total\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isUmJJ1SS5r0",
        "outputId": "d39a7d8d-5588-4027-b851-9c3006238b52"
      },
      "source": [
        "path_test_data='/content/drive/MyDrive/translateMS/data/theoretical_preprocessed_test_data.tfrecords'\n",
        "\n",
        "test_dataset = tf.data.TFRecordDataset(path_test_data).map(parse_function).shuffle(400000).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "for mz, seq in test_dataset:\n",
        "  print(mz,seq)\n",
        "  break  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[     1   8206   8304  10007  13908  14007  15709  15710  15809  17511\n",
            "  26714  26812  28515  28516  28615  30317  39520  39618  39825  39923\n",
            "  41321  41626  45222  45320  47023  55435  55533  56725  56823  57236\n",
            "  58526  65428  65526  65539  65638  67229  67341  75446  75545  76832\n",
            "  76931  77247  78633  84150  84248  85951  88237  88335  90038  95458\n",
            "  95556  97259  99641  99739 101442 106766 106865 108567 110949 111048\n",
            " 112750 118075 118173 119652 119751 119876 121453 125178 125277 126980\n",
            " 129358 129456 131159 136487 136585 138288 144065 144163 145190 145288\n",
            " 145866 146991 152768 152866 154569 159897 159995 161698 164076 164175\n",
            " 165877 169602 169701 171180 171278 171403 172981 178305 178404 180106\n",
            " 182488 182587 184289 189614 189712 191415 193797 193895 195598 201018\n",
            " 201116 202819 205105 205203 206906 212422 212521 213808 213907 214223\n",
            " 215609 223715 223814 223827 223925 225516 225628 232530 232628 233820\n",
            " 233918 234331 235621 244033 244131 245834 249430 249528 249735 249833\n",
            " 251231 251536 260738 260837 262539 262541 262639 264342 273544 273643\n",
            " 275345 275346 275445 277147 281049 281147 282850 292656      2], shape=(159,), dtype=int64) tf.Tensor(\n",
            "[ 1  5 19 15 15 19  4  6  9  9  9  8  6 17 11  6  8 13  8  8  8  6  5 16\n",
            " 18  8 15 18  2], shape=(29,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya5dz1FP3b3m",
        "outputId": "5834cccd-0a41-427e-8171-c3b039aa44c4"
      },
      "source": [
        "test_loss, test_accuracy = evaluate_aminoacid_level(test_dataset)\n",
        "print(f'\\ttest | Loss {valid_loss:.3f}, Accuracy {test_accuracy:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ttest | Loss 0.003, Accuracy 0.999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BoCyE4UxbNy",
        "outputId": "84439f01-c743-44c1-9602-a9af94eb7e4a"
      },
      "source": [
        "accuracy_test_data = evaluate_peptide_level(test_dataset.take(2000))\n",
        "print(f'Accuracy of test data for peptide level : {accuracy_test_data:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 1.0\n",
            "20 1.0\n",
            "30 1.0\n",
            "40 1.0\n",
            "50 0.9795918367346939\n",
            "60 0.9661016949152542\n",
            "70 0.9710144927536232\n",
            "80 0.9746835443037974\n",
            "90 0.9775280898876404\n",
            "100 0.9797979797979798\n",
            "110 0.981651376146789\n",
            "120 0.9831932773109243\n",
            "130 0.9844961240310077\n",
            "140 0.9856115107913669\n",
            "150 0.9865771812080537\n",
            "160 0.9874213836477987\n",
            "170 0.9881656804733728\n",
            "180 0.9888268156424581\n",
            "190 0.9894179894179894\n",
            "200 0.9899497487437185\n",
            "210 0.9904306220095693\n",
            "220 0.9908675799086758\n",
            "230 0.9912663755458515\n",
            "240 0.9916317991631799\n",
            "250 0.9919678714859438\n",
            "260 0.9922779922779923\n",
            "270 0.9925650557620818\n",
            "280 0.992831541218638\n",
            "290 0.9930795847750865\n",
            "300 0.9933110367892977\n",
            "310 0.9935275080906149\n",
            "320 0.9937304075235109\n",
            "330 0.993920972644377\n",
            "340 0.9941002949852508\n",
            "350 0.994269340974212\n",
            "360 0.9944289693593314\n",
            "370 0.994579945799458\n",
            "380 0.9920844327176781\n",
            "390 0.9897172236503856\n",
            "400 0.9899749373433584\n",
            "410 0.9902200488997555\n",
            "420 0.9904534606205251\n",
            "430 0.9906759906759907\n",
            "440 0.9908883826879271\n",
            "450 0.9910913140311804\n",
            "460 0.9912854030501089\n",
            "470 0.9914712153518124\n",
            "480 0.9916492693110647\n",
            "490 0.9918200408997955\n",
            "500 0.9919839679358717\n",
            "510 0.9921414538310412\n",
            "520 0.9922928709055877\n",
            "530 0.9924385633270322\n",
            "540 0.9925788497217068\n",
            "550 0.9927140255009107\n",
            "560 0.9928443649373881\n",
            "570 0.9929701230228472\n",
            "580 0.9930915371329879\n",
            "590 0.9932088285229203\n",
            "600 0.993322203672788\n",
            "610 0.993431855500821\n",
            "620 0.9935379644588045\n",
            "630 0.9936406995230525\n",
            "640 0.9921752738654147\n",
            "650 0.9907550077041603\n",
            "660 0.9893778452200304\n",
            "670 0.9880418535127056\n",
            "680 0.9882179675994109\n",
            "690 0.9854862119013063\n",
            "700 0.9856938483547926\n",
            "710 0.9858956276445698\n",
            "720 0.9860917941585535\n",
            "730 0.9862825788751715\n",
            "740 0.986468200270636\n",
            "750 0.986648865153538\n",
            "760 0.9868247694334651\n",
            "770 0.9869960988296489\n",
            "780 0.9871630295250321\n",
            "790 0.9873257287705957\n",
            "800 0.9874843554443054\n",
            "810 0.9864029666254636\n",
            "820 0.9865689865689866\n",
            "830 0.9867310012062727\n",
            "840 0.9868891537544696\n",
            "850 0.9858657243816255\n",
            "860 0.9860302677532014\n",
            "870 0.9861910241657077\n",
            "880 0.9863481228668942\n",
            "890 0.9865016872890888\n",
            "900 0.9866518353726362\n",
            "910 0.9867986798679867\n",
            "920 0.9869423286180631\n",
            "930 0.9870828848223897\n",
            "940 0.987220447284345\n",
            "950 0.9873551106427819\n",
            "960 0.9874869655891554\n",
            "970 0.9876160990712074\n",
            "980 0.9877425944841676\n",
            "990 0.9878665318503539\n",
            "1000 0.987987987987988\n",
            "1010 0.9871159563924677\n",
            "1020 0.9872423945044161\n",
            "1030 0.9873663751214772\n",
            "1040 0.9865255052935515\n",
            "1050 0.9866539561487131\n",
            "1060 0.9867799811142587\n",
            "1070 0.9869036482694107\n",
            "1080 0.9870250231696015\n",
            "1090 0.9871441689623508\n",
            "1100 0.9872611464968153\n",
            "1110 0.9873760144274121\n",
            "1120 0.9874888293118856\n",
            "1130 0.9875996457041629\n",
            "1140 0.9877085162423178\n",
            "1150 0.9878154917319408\n",
            "1160 0.9879206212251941\n",
            "1170 0.9880239520958084\n",
            "1180 0.9881255301102629\n",
            "1190 0.9882253994953742\n",
            "1200 0.987489574645538\n",
            "1210 0.9875930521091811\n",
            "1220 0.9876948318293683\n",
            "1230 0.9877949552481693\n",
            "1240 0.9878934624697336\n",
            "1250 0.9879903923138511\n",
            "1260 0.9880857823669579\n",
            "1270 0.9881796690307328\n",
            "1280 0.9882720875684128\n",
            "1290 0.9883630721489527\n",
            "1300 0.9884526558891455\n",
            "1310 0.988540870893812\n",
            "1320 0.9886277482941622\n",
            "1330 0.9887133182844243\n",
            "1340 0.9887976101568334\n",
            "1350 0.9888806523350631\n",
            "1360 0.9889624724061811\n",
            "1370 0.9890430971512053\n",
            "1380 0.9891225525743292\n",
            "1390 0.9892008639308856\n",
            "1400 0.9892780557541101\n",
            "1410 0.9893541518807665\n",
            "1420 0.9894291754756871\n",
            "1430 0.9895031490552834\n",
            "1440 0.9895760945100764\n",
            "1450 0.989648033126294\n",
            "1460 0.9897189856065799\n",
            "1470 0.989788972089857\n",
            "1480 0.9898580121703854\n",
            "1490 0.989926124916051\n",
            "1500 0.989993328885924\n",
            "1510 0.9900596421471173\n",
            "1520 0.989466754443713\n",
            "1530 0.9895356442119032\n",
            "1540 0.9896036387264457\n",
            "1550 0.9896707553260168\n",
            "1560 0.9897370109044259\n",
            "1570 0.9898024219247928\n",
            "1580 0.9898670044331855\n",
            "1590 0.9899307740717432\n",
            "1600 0.9899937460913071\n",
            "1610 0.9900559353635798\n",
            "1620 0.990117356392835\n",
            "1630 0.9895641497851443\n",
            "1640 0.9896278218425869\n",
            "1650 0.9896907216494846\n",
            "1660 0.9897528631705846\n",
            "1670 0.9898142600359496\n",
            "1680 0.9898749255509232\n",
            "1690 0.9899348727057431\n",
            "1700 0.9899941141848146\n",
            "1710 0.9900526623756583\n",
            "1720 0.9901105293775451\n",
            "1730 0.9901677270098322\n",
            "1740 0.9896492236917769\n",
            "1750 0.9897084048027445\n",
            "1760 0.9891984081864695\n",
            "1770 0.9886941775014132\n",
            "1780 0.9887577290612704\n",
            "1790 0.9877026271660145\n",
            "1800 0.9877709838799333\n",
            "1810 0.9872857932559425\n",
            "1820 0.9868059373282023\n",
            "1830 0.9868780754510662\n",
            "1840 0.9869494290375204\n",
            "1850 0.9864791779340184\n",
            "1860 0.9865519096288327\n",
            "1870 0.9860888175494917\n",
            "1880 0.9861628525811602\n",
            "1890 0.9857067231339333\n",
            "1900 0.985781990521327\n",
            "1910 0.9858564693556836\n",
            "1920 0.9859301719645649\n",
            "1930 0.9860031104199067\n",
            "1940 0.9860752965446106\n",
            "1950 0.9861467419189328\n",
            "1960 0.9857069933639612\n",
            "1970 0.9857795835449467\n",
            "1980 0.9858514401212733\n",
            "1990 0.9859225741578683\n",
            "2000 0.9859929964982491\n",
            "Accuracy of test data for peptide level : 0.9860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBJpmj0GvxtJ"
      },
      "source": [
        "Evaluate real data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9QZTIz8UnnK"
      },
      "source": [
        "path_real_test_dataset='/content/drive/MyDrive/translateMS/data/real_preprocessed_test_data.tfrecords'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezrnv2NAv1oN",
        "outputId": "3063a04f-e0eb-4da3-f378-bb9103ceb26f"
      },
      "source": [
        "real_test_dataset = tf.data.TFRecordDataset(path_real_test_dataset).map(parse_function).shard(num_shards=10, index=0)\n",
        "real_test_dataset = real_test_dataset.shuffle(40000)\n",
        "\n",
        "real_test_loss, real_test_accuracy = evaluate_aminoacid_level(real_test_dataset)\n",
        "\n",
        "print(f'\\tReal test data | Loss {real_test_loss:.3f}, Accuracy {real_test_accuracy:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tReal test data | Loss 9.726, Accuracy 0.136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NgbP1fRBUgNR",
        "outputId": "2554cf2b-a464-42ca-8b74-6c9191e7e90e"
      },
      "source": [
        "accuracy_test_data = evaluate_peptide_level(real_test_dataset)\n",
        "print(f'Accuracy of real test data for peptide level : {accuracy_test_data:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 0.0\n",
            "20 0.0\n",
            "30 0.0\n",
            "40 0.0\n",
            "50 0.0\n",
            "60 0.0\n",
            "70 0.0\n",
            "80 0.0\n",
            "90 0.0\n",
            "100 0.0\n",
            "110 0.0\n",
            "120 0.0\n",
            "130 0.0\n",
            "140 0.0\n",
            "150 0.0\n",
            "160 0.0\n",
            "170 0.0\n",
            "180 0.0\n",
            "190 0.0\n",
            "200 0.0\n",
            "210 0.0\n",
            "220 0.0\n",
            "230 0.0\n",
            "240 0.0\n",
            "250 0.0\n",
            "260 0.0\n",
            "270 0.0\n",
            "280 0.0\n",
            "290 0.0\n",
            "300 0.0\n",
            "310 0.0\n",
            "320 0.0\n",
            "330 0.0\n",
            "340 0.0\n",
            "350 0.0\n",
            "360 0.0\n",
            "370 0.0\n",
            "380 0.0\n",
            "390 0.0\n",
            "400 0.0\n",
            "410 0.0\n",
            "420 0.0\n",
            "430 0.0\n",
            "440 0.0\n",
            "450 0.0\n",
            "460 0.0\n",
            "470 0.0\n",
            "480 0.0\n",
            "490 0.0\n",
            "500 0.0\n",
            "510 0.0\n",
            "520 0.0\n",
            "530 0.0\n",
            "540 0.0\n",
            "550 0.0\n",
            "560 0.0\n",
            "570 0.0\n",
            "580 0.0\n",
            "590 0.0\n",
            "600 0.0\n",
            "610 0.0\n",
            "620 0.0\n",
            "630 0.0\n",
            "640 0.0\n",
            "650 0.0\n",
            "660 0.0\n",
            "670 0.0\n",
            "680 0.0\n",
            "690 0.0\n",
            "700 0.0\n",
            "710 0.0\n",
            "720 0.0\n",
            "730 0.0\n",
            "740 0.0\n",
            "750 0.0\n",
            "760 0.0\n",
            "770 0.0\n",
            "780 0.0\n",
            "790 0.0\n",
            "800 0.0\n",
            "810 0.0\n",
            "820 0.0\n",
            "830 0.0\n",
            "840 0.0\n",
            "850 0.0\n",
            "860 0.0\n",
            "870 0.0\n",
            "880 0.0\n",
            "890 0.0\n",
            "900 0.0\n",
            "910 0.0\n",
            "920 0.0\n",
            "930 0.0\n",
            "940 0.0\n",
            "950 0.0\n",
            "960 0.0\n",
            "970 0.0\n",
            "980 0.0\n",
            "990 0.0\n",
            "1000 0.0\n",
            "1010 0.0\n",
            "1020 0.0\n",
            "1030 0.0\n",
            "1040 0.0\n",
            "1050 0.0\n",
            "1060 0.0\n",
            "1070 0.0\n",
            "1080 0.0\n",
            "1090 0.0\n",
            "1100 0.0\n",
            "1110 0.0\n",
            "1120 0.0\n",
            "1130 0.0\n",
            "1140 0.0\n",
            "1150 0.0\n",
            "1160 0.0\n",
            "1170 0.0\n",
            "1180 0.0\n",
            "1190 0.0\n",
            "1200 0.0\n",
            "1210 0.0\n",
            "1220 0.0\n",
            "1230 0.0\n",
            "1240 0.0\n",
            "1250 0.0\n",
            "1260 0.0\n",
            "1270 0.0\n",
            "1280 0.0\n",
            "1290 0.0\n",
            "1300 0.0\n",
            "1310 0.0\n",
            "1320 0.0\n",
            "1330 0.0\n",
            "1340 0.0\n",
            "1350 0.0\n",
            "1360 0.0\n",
            "1370 0.0\n",
            "1380 0.0\n",
            "1390 0.0\n",
            "1400 0.0\n",
            "1410 0.0\n",
            "1420 0.0\n",
            "1430 0.0\n",
            "1440 0.0\n",
            "1450 0.0\n",
            "1460 0.0\n",
            "1470 0.0\n",
            "1480 0.0\n",
            "1490 0.0\n",
            "1500 0.0\n",
            "1510 0.0\n",
            "1520 0.0\n",
            "1530 0.0\n",
            "1540 0.0\n",
            "1550 0.0\n",
            "1560 0.0\n",
            "1570 0.0\n",
            "1580 0.0\n",
            "1590 0.0\n",
            "1600 0.0\n",
            "1610 0.0\n",
            "1620 0.0\n",
            "1630 0.0\n",
            "1640 0.0\n",
            "1650 0.0\n",
            "1660 0.0\n",
            "1670 0.0\n",
            "1680 0.0\n",
            "1690 0.0\n",
            "1700 0.0\n",
            "1710 0.0\n",
            "1720 0.0\n",
            "1730 0.0\n",
            "1740 0.0\n",
            "1750 0.0\n",
            "1760 0.0\n",
            "1770 0.0\n",
            "1780 0.0\n",
            "1790 0.0\n",
            "1800 0.0\n",
            "1810 0.0\n",
            "1820 0.0\n",
            "1830 0.0\n",
            "1840 0.0\n",
            "1850 0.0\n",
            "1860 0.0\n",
            "1870 0.0\n",
            "1880 0.0\n",
            "1890 0.0\n",
            "1900 0.0\n",
            "1910 0.0\n",
            "1920 0.0\n",
            "1930 0.0\n",
            "1940 0.0\n",
            "1950 0.0\n",
            "1960 0.0\n",
            "1970 0.0\n",
            "1980 0.0\n",
            "1990 0.0\n",
            "2000 0.0\n",
            "2010 0.0\n",
            "2020 0.0\n",
            "2030 0.0\n",
            "2040 0.0\n",
            "2050 0.0\n",
            "2060 0.0\n",
            "2070 0.0\n",
            "2080 0.0\n",
            "2090 0.0\n",
            "2100 0.0\n",
            "2110 0.0\n",
            "2120 0.0\n",
            "2130 0.0\n",
            "2140 0.0\n",
            "2150 0.0\n",
            "2160 0.0\n",
            "2170 0.0\n",
            "2180 0.0\n",
            "2190 0.0\n",
            "2200 0.0\n",
            "2210 0.0\n",
            "2220 0.0\n",
            "2230 0.0\n",
            "2240 0.0\n",
            "2250 0.0\n",
            "2260 0.0\n",
            "2270 0.0\n",
            "2280 0.0\n",
            "2290 0.0\n",
            "2300 0.0\n",
            "2310 0.0\n",
            "2320 0.0\n",
            "2330 0.0\n",
            "2340 0.0\n",
            "2350 0.0\n",
            "2360 0.0\n",
            "2370 0.0\n",
            "2380 0.0\n",
            "2390 0.0\n",
            "2400 0.0\n",
            "2410 0.0\n",
            "2420 0.0\n",
            "2430 0.0\n",
            "2440 0.0\n",
            "2450 0.0\n",
            "2460 0.0\n",
            "2470 0.0\n",
            "2480 0.0\n",
            "2490 0.0\n",
            "2500 0.0\n",
            "2510 0.0\n",
            "2520 0.0\n",
            "2530 0.0\n",
            "2540 0.0\n",
            "2550 0.0\n",
            "2560 0.0\n",
            "2570 0.0\n",
            "2580 0.0\n",
            "2590 0.0\n",
            "2600 0.0\n",
            "2610 0.0\n",
            "2620 0.0\n",
            "2630 0.0\n",
            "2640 0.0\n",
            "2650 0.0\n",
            "2660 0.0\n",
            "2670 0.0\n",
            "2680 0.0\n",
            "2690 0.0\n",
            "2700 0.0\n",
            "2710 0.0\n",
            "2720 0.0\n",
            "2730 0.0\n",
            "2740 0.0\n",
            "2750 0.0\n",
            "2760 0.0\n",
            "2770 0.0\n",
            "2780 0.0\n",
            "2790 0.0\n",
            "2800 0.0\n",
            "2810 0.0\n",
            "2820 0.0\n",
            "2830 0.0\n",
            "2840 0.0\n",
            "2850 0.0\n",
            "2860 0.0\n",
            "2870 0.0\n",
            "2880 0.0\n",
            "2890 0.0\n",
            "2900 0.0\n",
            "2910 0.0\n",
            "2920 0.0\n",
            "2930 0.0\n",
            "2940 0.0\n",
            "2950 0.0\n",
            "2960 0.0\n",
            "2970 0.0\n",
            "2980 0.0\n",
            "2990 0.0\n",
            "3000 0.0\n",
            "3010 0.0\n",
            "3020 0.0\n",
            "3030 0.0\n",
            "3040 0.0\n",
            "3050 0.0\n",
            "3060 0.0\n",
            "3070 0.0\n",
            "3080 0.0\n",
            "3090 0.0\n",
            "3100 0.0\n",
            "3110 0.0\n",
            "3120 0.0\n",
            "3130 0.0\n",
            "3140 0.0\n",
            "3150 0.0\n",
            "3160 0.0\n",
            "3170 0.0\n",
            "3180 0.0\n",
            "3190 0.0\n",
            "3200 0.0\n",
            "3210 0.0\n",
            "3220 0.0\n",
            "3230 0.0\n",
            "3240 0.0\n",
            "3250 0.0\n",
            "3260 0.0\n",
            "3270 0.0\n",
            "3280 0.0\n",
            "3290 0.0\n",
            "3300 0.0\n",
            "3310 0.0\n",
            "3320 0.0\n",
            "3330 0.0\n",
            "3340 0.0\n",
            "3350 0.0\n",
            "3360 0.0\n",
            "3370 0.0\n",
            "3380 0.0\n",
            "3390 0.0\n",
            "3400 0.0\n",
            "3410 0.0\n",
            "3420 0.0\n",
            "3430 0.0\n",
            "3440 0.0\n",
            "3450 0.0\n",
            "3460 0.0\n",
            "3470 0.0\n",
            "3480 0.0\n",
            "3490 0.0\n",
            "3500 0.0\n",
            "3510 0.0\n",
            "3520 0.0\n",
            "3530 0.0\n",
            "3540 0.0\n",
            "3550 0.0\n",
            "3560 0.0\n",
            "3570 0.0\n",
            "3580 0.0\n",
            "3590 0.0\n",
            "3600 0.0\n",
            "3610 0.0\n",
            "3620 0.0\n",
            "3630 0.0\n",
            "3640 0.0\n",
            "3650 0.0\n",
            "3660 0.0\n",
            "3670 0.0\n",
            "3680 0.0\n",
            "3690 0.0\n",
            "3700 0.0\n",
            "3710 0.0\n",
            "3720 0.0\n",
            "3730 0.0\n",
            "3740 0.0\n",
            "3750 0.0\n",
            "3760 0.0\n",
            "3770 0.0\n",
            "3780 0.0\n",
            "3790 0.0\n",
            "3800 0.0\n",
            "3810 0.0\n",
            "3820 0.0\n",
            "3830 0.0\n",
            "3840 0.0\n",
            "3850 0.0\n",
            "3860 0.0\n",
            "3870 0.0\n",
            "3880 0.0\n",
            "3890 0.0\n",
            "3900 0.0\n",
            "3910 0.0\n",
            "3920 0.0\n",
            "3930 0.0\n",
            "3940 0.0\n",
            "3950 0.0\n",
            "3960 0.0\n",
            "3970 0.0\n",
            "3980 0.0\n",
            "3990 0.0\n",
            "4000 0.0\n",
            "4010 0.0\n",
            "4020 0.0\n",
            "4030 0.0\n",
            "4040 0.0\n",
            "4050 0.0\n",
            "4060 0.0\n",
            "4070 0.0\n",
            "4080 0.0\n",
            "4090 0.0\n",
            "4100 0.0\n",
            "4110 0.0\n",
            "4120 0.0\n",
            "4130 0.0\n",
            "4140 0.0\n",
            "4150 0.0\n",
            "4160 0.0\n",
            "4170 0.0\n",
            "4180 0.0\n",
            "4190 0.0\n",
            "4200 0.0\n",
            "4210 0.0\n",
            "4220 0.0\n",
            "4230 0.0\n",
            "4240 0.0\n",
            "4250 0.0\n",
            "4260 0.0\n",
            "4270 0.0\n",
            "4280 0.0\n",
            "4290 0.0\n",
            "4300 0.0\n",
            "4310 0.0\n",
            "4320 0.0\n",
            "4330 0.0\n",
            "4340 0.0\n",
            "4350 0.0\n",
            "4360 0.0\n",
            "4370 0.0\n",
            "4380 0.0\n",
            "4390 0.0\n",
            "4400 0.0\n",
            "4410 0.0\n",
            "4420 0.0\n",
            "4430 0.0\n",
            "4440 0.0\n",
            "4450 0.0\n",
            "4460 0.0\n",
            "4470 0.0\n",
            "4480 0.0\n",
            "4490 0.0\n",
            "4500 0.0\n",
            "4510 0.0\n",
            "4520 0.0\n",
            "4530 0.0\n",
            "4540 0.0\n",
            "4550 0.0\n",
            "4560 0.0\n",
            "4570 0.0\n",
            "4580 0.0\n",
            "4590 0.0\n",
            "4600 0.0\n",
            "4610 0.0\n",
            "4620 0.0\n",
            "4630 0.0\n",
            "4640 0.0\n",
            "4650 0.0\n",
            "4660 0.0\n",
            "4670 0.0\n",
            "4680 0.0\n",
            "4690 0.0\n",
            "4700 0.0\n",
            "4710 0.0\n",
            "4720 0.0\n",
            "4730 0.0\n",
            "4740 0.0\n",
            "4750 0.0\n",
            "4760 0.0\n",
            "4770 0.0\n",
            "4780 0.0\n",
            "4790 0.0\n",
            "4800 0.0\n",
            "4810 0.0\n",
            "4820 0.0\n",
            "4830 0.0\n",
            "4840 0.0\n",
            "4850 0.0\n",
            "4860 0.0\n",
            "4870 0.0\n",
            "4880 0.0\n",
            "4890 0.0\n",
            "4900 0.0\n",
            "4910 0.0\n",
            "4920 0.0\n",
            "4930 0.0\n",
            "4940 0.0\n",
            "4950 0.0\n",
            "4960 0.0\n",
            "4970 0.0\n",
            "4980 0.0\n",
            "4990 0.0\n",
            "5000 0.0\n",
            "5010 0.0\n",
            "5020 0.0\n",
            "5030 0.0\n",
            "5040 0.0\n",
            "5050 0.0\n",
            "5060 0.0\n",
            "5070 0.0\n",
            "5080 0.0\n",
            "5090 0.0\n",
            "5100 0.0\n",
            "5110 0.0\n",
            "5120 0.0\n",
            "5130 0.0\n",
            "5140 0.0\n",
            "5150 0.0\n",
            "5160 0.0\n",
            "5170 0.0\n",
            "5180 0.0\n",
            "5190 0.0\n",
            "5200 0.0\n",
            "5210 0.0\n",
            "5220 0.0\n",
            "5230 0.0\n",
            "5240 0.0\n",
            "5250 0.0\n",
            "5260 0.0\n",
            "5270 0.0\n",
            "5280 0.0\n",
            "5290 0.0\n",
            "5300 0.0\n",
            "5310 0.0\n",
            "5320 0.0\n",
            "5330 0.0\n",
            "5340 0.0\n",
            "5350 0.0\n",
            "5360 0.0\n",
            "5370 0.0\n",
            "5380 0.0\n",
            "5390 0.0\n",
            "5400 0.0\n",
            "5410 0.0\n",
            "5420 0.0\n",
            "5430 0.0\n",
            "5440 0.0\n",
            "5450 0.0\n",
            "5460 0.0\n",
            "5470 0.0\n",
            "5480 0.0\n",
            "5490 0.0\n",
            "5500 0.0\n",
            "5510 0.0\n",
            "5520 0.0\n",
            "5530 0.0\n",
            "5540 0.0\n",
            "5550 0.0\n",
            "5560 0.0\n",
            "5570 0.0\n",
            "5580 0.0\n",
            "5590 0.0\n",
            "5600 0.0\n",
            "5610 0.0\n",
            "5620 0.0\n",
            "5630 0.0\n",
            "5640 0.0\n",
            "5650 0.0\n",
            "5660 0.0\n",
            "5670 0.0\n",
            "5680 0.0\n",
            "5690 0.0\n",
            "5700 0.0\n",
            "5710 0.0\n",
            "5720 0.0\n",
            "5730 0.0\n",
            "5740 0.0\n",
            "5750 0.0\n",
            "5760 0.0\n",
            "5770 0.0\n",
            "5780 0.0\n",
            "5790 0.0\n",
            "5800 0.0\n",
            "5810 0.0\n",
            "5820 0.0\n",
            "5830 0.0\n",
            "5840 0.0\n",
            "5850 0.0\n",
            "5860 0.0\n",
            "5870 0.0\n",
            "5880 0.0\n",
            "5890 0.0\n",
            "5900 0.0\n",
            "5910 0.0\n",
            "5920 0.0\n",
            "5930 0.0\n",
            "5940 0.0\n",
            "5950 0.0\n",
            "5960 0.0\n",
            "5970 0.0\n",
            "5980 0.0\n",
            "5990 0.0\n",
            "6000 0.0\n",
            "6010 0.0\n",
            "6020 0.0\n",
            "6030 0.0\n",
            "6040 0.0\n",
            "6050 0.0\n",
            "6060 0.0\n",
            "6070 0.0\n",
            "6080 0.0\n",
            "6090 0.0\n",
            "6100 0.0\n",
            "6110 0.0\n",
            "6120 0.0\n",
            "6130 0.0\n",
            "6140 0.0\n",
            "6150 0.0\n",
            "6160 0.0\n",
            "6170 0.0\n",
            "6180 0.0\n",
            "6190 0.0\n",
            "6200 0.0\n",
            "6210 0.0\n",
            "6220 0.0\n",
            "6230 0.0\n",
            "6240 0.0\n",
            "6250 0.0\n",
            "6260 0.0\n",
            "6270 0.0\n",
            "6280 0.0\n",
            "6290 0.0\n",
            "6300 0.0\n",
            "6310 0.0\n",
            "6320 0.0\n",
            "6330 0.0\n",
            "6340 0.0\n",
            "6350 0.0\n",
            "6360 0.0\n",
            "6370 0.0\n",
            "6380 0.0\n",
            "6390 0.0\n",
            "6400 0.0\n",
            "6410 0.0\n",
            "6420 0.0\n",
            "6430 0.0\n",
            "6440 0.0\n",
            "6450 0.0\n",
            "6460 0.0\n",
            "6470 0.0\n",
            "6480 0.0\n",
            "6490 0.0\n",
            "6500 0.0\n",
            "6510 0.0\n",
            "6520 0.0\n",
            "6530 0.0\n",
            "6540 0.0\n",
            "6550 0.0\n",
            "6560 0.0\n",
            "6570 0.0\n",
            "6580 0.0\n",
            "6590 0.0\n",
            "6600 0.0\n",
            "6610 0.0\n",
            "6620 0.0\n",
            "6630 0.0\n",
            "6640 0.0\n",
            "6650 0.0\n",
            "6660 0.0\n",
            "6670 0.0\n",
            "6680 0.0\n",
            "6690 0.0\n",
            "6700 0.0\n",
            "6710 0.0\n",
            "6720 0.0\n",
            "6730 0.0\n",
            "6740 0.0\n",
            "6750 0.0\n",
            "6760 0.0\n",
            "6770 0.0\n",
            "6780 0.0\n",
            "6790 0.0\n",
            "6800 0.0\n",
            "6810 0.0\n",
            "6820 0.0\n",
            "6830 0.0\n",
            "6840 0.0\n",
            "6850 0.0\n",
            "6860 0.0\n",
            "6870 0.0\n",
            "6880 0.0\n",
            "6890 0.0\n",
            "6900 0.0\n",
            "6910 0.0\n",
            "6920 0.0\n",
            "6930 0.0\n",
            "6940 0.0\n",
            "6950 0.0\n",
            "6960 0.0\n",
            "6970 0.0\n",
            "6980 0.0\n",
            "6990 0.0\n",
            "7000 0.0\n",
            "7010 0.0\n",
            "7020 0.0\n",
            "7030 0.0\n",
            "7040 0.0\n",
            "7050 0.0\n",
            "7060 0.0\n",
            "7070 0.0\n",
            "7080 0.0\n",
            "7090 0.0\n",
            "7100 0.0\n",
            "7110 0.0\n",
            "7120 0.0\n",
            "7130 0.0\n",
            "7140 0.0\n",
            "7150 0.0\n",
            "7160 0.0\n",
            "7170 0.0\n",
            "7180 0.0\n",
            "7190 0.0\n",
            "7200 0.0\n",
            "7210 0.0\n",
            "7220 0.0\n",
            "7230 0.0\n",
            "7240 0.0\n",
            "7250 0.0\n",
            "7260 0.0\n",
            "7270 0.0\n",
            "7280 0.0\n",
            "7290 0.0\n",
            "7300 0.0\n",
            "7310 0.0\n",
            "7320 0.0\n",
            "7330 0.0\n",
            "7340 0.0\n",
            "7350 0.0\n",
            "7360 0.0\n",
            "7370 0.0\n",
            "7380 0.0\n",
            "7390 0.0\n",
            "7400 0.0\n",
            "7410 0.0\n",
            "7420 0.0\n",
            "7430 0.0\n",
            "7440 0.0\n",
            "7450 0.0\n",
            "7460 0.0\n",
            "7470 0.0\n",
            "7480 0.0\n",
            "7490 0.0\n",
            "7500 0.0\n",
            "7510 0.0\n",
            "7520 0.0\n",
            "7530 0.0\n",
            "7540 0.0\n",
            "7550 0.0\n",
            "7560 0.0\n",
            "7570 0.0\n",
            "7580 0.0\n",
            "7590 0.0\n",
            "7600 0.0\n",
            "7610 0.0\n",
            "7620 0.0\n",
            "7630 0.0\n",
            "7640 0.0\n",
            "7650 0.0\n",
            "7660 0.0\n",
            "7670 0.0\n",
            "7680 0.0\n",
            "7690 0.0\n",
            "7700 0.0\n",
            "7710 0.0\n",
            "7720 0.0\n",
            "7730 0.0\n",
            "7740 0.0\n",
            "7750 0.0\n",
            "7760 0.0\n",
            "7770 0.0\n",
            "7780 0.0\n",
            "7790 0.0\n",
            "7800 0.0\n",
            "7810 0.0\n",
            "7820 0.0\n",
            "7830 0.0\n",
            "7840 0.0\n",
            "7850 0.0\n",
            "7860 0.0\n",
            "7870 0.0\n",
            "7880 0.0\n",
            "7890 0.0\n",
            "7900 0.0\n",
            "7910 0.0\n",
            "7920 0.0\n",
            "7930 0.0\n",
            "7940 0.0\n",
            "7950 0.0\n",
            "7960 0.0\n",
            "7970 0.0\n",
            "7980 0.0\n",
            "7990 0.0\n",
            "8000 0.0\n",
            "8010 0.0\n",
            "8020 0.0\n",
            "8030 0.0\n",
            "8040 0.0\n",
            "8050 0.0\n",
            "8060 0.0\n",
            "8070 0.0\n",
            "8080 0.0\n",
            "8090 0.0\n",
            "8100 0.0\n",
            "8110 0.0\n",
            "8120 0.0\n",
            "8130 0.0\n",
            "8140 0.0\n",
            "8150 0.0\n",
            "8160 0.0\n",
            "8170 0.0\n",
            "8180 0.0\n",
            "8190 0.0\n",
            "8200 0.0\n",
            "8210 0.0\n",
            "8220 0.0\n",
            "8230 0.0\n",
            "8240 0.0\n",
            "8250 0.0\n",
            "8260 0.0\n",
            "8270 0.0\n",
            "8280 0.0\n",
            "8290 0.0\n",
            "8300 0.0\n",
            "8310 0.0\n",
            "8320 0.0\n",
            "8330 0.0\n",
            "8340 0.0\n",
            "8350 0.0\n",
            "8360 0.0\n",
            "8370 0.0\n",
            "8380 0.0\n",
            "8390 0.0\n",
            "8400 0.0\n",
            "8410 0.0\n",
            "8420 0.0\n",
            "8430 0.0\n",
            "8440 0.0\n",
            "8450 0.0\n",
            "8460 0.0\n",
            "8470 0.0\n",
            "8480 0.0\n",
            "8490 0.0\n",
            "8500 0.0\n",
            "8510 0.0\n",
            "8520 0.0\n",
            "8530 0.0\n",
            "8540 0.0\n",
            "8550 0.0\n",
            "8560 0.0\n",
            "8570 0.0\n",
            "8580 0.0\n",
            "8590 0.0\n",
            "8600 0.0\n",
            "8610 0.0\n",
            "8620 0.0\n",
            "8630 0.0\n",
            "8640 0.0\n",
            "8650 0.0\n",
            "8660 0.0\n",
            "8670 0.0\n",
            "8680 0.0\n",
            "8690 0.0\n",
            "8700 0.0\n",
            "8710 0.0\n",
            "8720 0.0\n",
            "8730 0.0\n",
            "8740 0.0\n",
            "8750 0.0\n",
            "8760 0.0\n",
            "8770 0.0\n",
            "8780 0.0\n",
            "8790 0.0\n",
            "8800 0.0\n",
            "8810 0.0\n",
            "8820 0.0\n",
            "8830 0.0\n",
            "8840 0.0\n",
            "8850 0.0\n",
            "8860 0.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c0971632dc48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_peptide_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_test_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy of real test data for peptide level : {accuracy_test_data:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-6afa23a34cb9>\u001b[0m in \u001b[0;36mevaluate_peptide_level\u001b[0;34m(dataset, max_length)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                    \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                    \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                    dec_padding_mask)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# select the last word from the seq_len dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-5225346b2fe1>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input, target, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;31m# dec_output.shape == (batch_size, tar_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     dec_output, attention_weights = self.decoder(\n\u001b[0;32m--> 285\u001b[0;31m         target, enc_output, training, look_ahead_mask, dec_padding_mask)\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, tar_seq_len, target_vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-5225346b2fe1>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m       x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n\u001b[0;32m--> 254\u001b[0;31m                                              look_ahead_mask, padding_mask)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mattention_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'decoder_layer{i+1}_block1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-5225346b2fe1>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_output, training, look_ahead_mask, padding_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     attn2, attn_weights_block2 = self.mha2(\n\u001b[0;32m--> 181\u001b[0;31m         enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0mattn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, target_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-5225346b2fe1>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, v, k, q, mask)\u001b[0m\n\u001b[1;32m    113\u001b[0m         q, k, v, mask)\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mscaled_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_len_q, num_heads, depth)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     concat_attention = tf.reshape(scaled_attention,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mtranspose_v2\u001b[0;34m(a, perm, conjugate, name)\u001b[0m\n\u001b[1;32m   2226\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m   \"\"\"\n\u001b[0;32m-> 2228\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconjugate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[1;32m   2307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mperm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2309\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtranspose_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(x, perm, name)\u001b[0m\n\u001b[1;32m  11652\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11653\u001b[0m       return transpose_eager_fallback(\n\u001b[0;32m> 11654\u001b[0;31m           x, perm, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m  11655\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11656\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose_eager_fallback\u001b[0;34m(x, perm, name, ctx)\u001b[0m\n\u001b[1;32m  11677\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tperm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tperm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11678\u001b[0m   _result = _execute.execute(b\"Transpose\", 1, inputs=_inputs_flat,\n\u001b[0;32m> 11679\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m  11680\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11681\u001b[0m     _execute.record_gradient(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vna6j2QjXzcs"
      },
      "source": [
        "# **Fine-tuning for real data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8edXMMpyX7-V"
      },
      "source": [
        "class Encoder2(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               intensity_vocab_size, dropout_rate=0.1):\n",
        "    super(Encoder2, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(intensity_vocab_size, self.d_model)\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x, intensity, training, mask):\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    intensity = self.embedding(intensity)  # (batch_size, intensity_seq_len, d_model)\n",
        "    x += intensity\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "\n",
        "class Decoder2(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "\n",
        "    super(Decoder2, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, dropout_rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights\n",
        "\n",
        "class ModifiedTransformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               intensity_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "      super(ModifiedTransformer, self).__init__()\n",
        "\n",
        "      self.encoder = Encoder2(num_layers, d_model, num_heads, dff,\n",
        "                              intensity_vocab_size, dropout_rate)\n",
        "\n",
        "      self.decoder = Decoder2(num_layers, d_model, num_heads,\n",
        "                              dff, dropout_rate)\n",
        "\n",
        "      self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, input, intensity, target, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "      enc_output = self.encoder(input, intensity, training, enc_padding_mask)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "      # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "      dec_output, attention_weights = self.decoder(\n",
        "          target, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "      final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "      return final_output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7KGTBoHPCDW"
      },
      "source": [
        "def create_masks(input, target):\n",
        "    # Encoder padding mask\n",
        "    enc_padding_mask = create_padding_mask(input)\n",
        "    # Used in the 2nd attention block in the decoder.\n",
        "    # This padding mask is used to mask the encoder outputs.\n",
        "    dec_padding_mask = create_padding_mask(input)\n",
        "    # Used in the 1st attention block in the decoder.\n",
        "    # It is used to pad and mask future tokens in the input received by\n",
        "    # the decoder.\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(target)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(target)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
        "\n",
        "\n",
        "'''\n",
        "d_model : input(embedding), ouput 차원\n",
        "num_layers : 인코더, 디코더 층\n",
        "num_heads : 멀티헤드 수\n",
        "d_ff : feedforward 차원 \n",
        "'''\n",
        "D_MODEL = 64\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 2\n",
        "DFF = 128\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywtqR8_OfUMp"
      },
      "source": [
        "def evaluate_aminoacid_level_finetuning(dataset):\n",
        "    batch_size = 64\n",
        "    num_batchs = 0\n",
        "    accuracy = 0\n",
        "    loss = 0\n",
        "    dataset_batchs = dataset.padded_batch(batch_size = batch_size, drop_remainder=True)\n",
        "\n",
        "    for batch, (input, intensity, target) in enumerate(dataset_batchs):\n",
        "        num_batchs = batch+1\n",
        "        target_input = target[:, :-1]\n",
        "        target_real = target[:, 1:]\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input, target_input)\n",
        "\n",
        "        encoder1_output, decoder1_output, _, _ = \\\n",
        "            pretrained_transformer(input,\n",
        "                                   target_input,\n",
        "                                   False,\n",
        "                                   enc_padding_mask,\n",
        "                                   combined_mask,\n",
        "                                   dec_padding_mask)\n",
        "\n",
        "        predictions, _ = modified_transformer(encoder1_output,\n",
        "                                              intensity,\n",
        "                                              decoder1_output,\n",
        "                                              False,\n",
        "                                              enc_padding_mask,\n",
        "                                              combined_mask,\n",
        "                                              dec_padding_mask)\n",
        "\n",
        "        loss += loss_function(target_real, predictions)\n",
        "        accuracy += accuracy_function(target_real, predictions)\n",
        "\n",
        "    return loss/num_batchs, accuracy/num_batchs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFcbS_-DYI8q"
      },
      "source": [
        "\n",
        "pretrained_transformer = Transformer(\n",
        "    num_layers=NUM_LAYERS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dff=DFF,\n",
        "    input_vocab_size=600000,\n",
        "    target_vocab_size=30,\n",
        "    positional_encoding_input = 1000,\n",
        "    positional_encoding_target = 50,\n",
        "    dropout_rate=DROPOUT_RATE)\n",
        "\n",
        "modified_transformer = ModifiedTransformer(\n",
        "    num_layers=NUM_LAYERS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dff=DFF,\n",
        "    intensity_vocab_size=12000,\n",
        "    target_vocab_size=30,\n",
        "    dropout_rate=DROPOUT_RATE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csElkUYQfuVM",
        "outputId": "c93147da-0fcf-4e89-d40d-80e7f1603980"
      },
      "source": [
        "#load pretraining checkpoint\n",
        "\n",
        "ckpt_path_pretraining = '/content/drive/MyDrive/translateMS/checkpoints/pretraining/ckpt-opt'\n",
        "\n",
        "ckpt_pretraining = tf.train.Checkpoint(transformer=pretrained_transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_pretraining.restore(ckpt_path_pretraining)\n",
        "print('Checkpoint restored!!')\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "#if ckpt_manager.latest_checkpoint:\n",
        "#    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "#    print('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint restored!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5RzT33xXYPrS",
        "outputId": "db267977-7108-4425-f9db-1e92c0ed8ac8"
      },
      "source": [
        "checkpoint_path_finetuning = \"/content/drive/MyDrive/translateMS/checkpoints/finetuning\"\n",
        "\n",
        "ckpt_finetuning = tf.train.Checkpoint(transformer=modified_transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager_finetuning = tf.train.CheckpointManager(ckpt_finetuning, checkpoint_path_finetuning, max_to_keep=10)\n",
        "'''\n",
        "if ckpt_manager_finetuning.latest_checkpoint:\n",
        "    print(ckpt_manager_finetuning.latest_checkpoint)\n",
        "    ckpt_finetuning.restore(ckpt_manager_finetuning.latest_checkpoint)\n",
        "    print('Latest checkpoint restored!!')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nif ckpt_manager_finetuning.latest_checkpoint:\\n    print(ckpt_manager_finetuning.latest_checkpoint)\\n    ckpt_finetuning.restore(ckpt_manager_finetuning.latest_checkpoint)\\n    print('Latest checkpoint restored!!')\\n\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W349ddqgkjKz"
      },
      "source": [
        "train_step_signature_finetuning = [\n",
        "  tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "  tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "  tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature_finetuning)\n",
        "def train_step_finetuning(input, intensity, target):\n",
        "\n",
        "    target_input = target[:, :-1]\n",
        "    target_real = target[:, 1:]\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input, target_input)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        #return : enc_output, dec_output, final_output, attention_weights\n",
        "        encoder1_output, decoder1_output, _, _ = \\\n",
        "            pretrained_transformer(input,\n",
        "                                   target_input,\n",
        "                                   False,\n",
        "                                   enc_padding_mask,\n",
        "                                   combined_mask,\n",
        "                                   dec_padding_mask)\n",
        "\n",
        "        predictions, _ = modified_transformer(encoder1_output,\n",
        "                                             intensity,\n",
        "                                             decoder1_output,\n",
        "                                             True,\n",
        "                                             enc_padding_mask,\n",
        "                                             combined_mask,\n",
        "                                             dec_padding_mask)\n",
        "\n",
        "        loss = loss_function(target_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, modified_transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, modified_transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy_function(target_real, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrMoHKUplnCa"
      },
      "source": [
        "feature_description = {\n",
        "            'sequence': tf.io.VarLenFeature(tf.int64),\n",
        "            'intensity': tf.io.VarLenFeature(tf.int64),\n",
        "            'mz': tf.io.VarLenFeature(tf.int64),\n",
        "            }\n",
        "\n",
        "def parse_function(example_proto):\n",
        "    parsed_example = tf.io.parse_single_example(example_proto,feature_description)\n",
        "    mz = parsed_example['mz'].values\n",
        "    intensity = parsed_example['intensity'].values\n",
        "    sequence = parsed_example['sequence'].values\n",
        "    return mz, intensity, sequence\n",
        "\n",
        "path_real_train_dataset='/content/drive/MyDrive/translateMS/data/real_preprocessed_train_data.tfrecords'\n",
        "path_real_valid_dataset='/content/drive/MyDrive/translateMS/data/real_preprocessed_test_data.tfrecords'\n",
        "path_real_test_dataset='/content/drive/MyDrive/translateMS/data/real_preprocessed_valid_data.tfrecords'\n",
        "\n",
        "\n",
        "size_dataset = 0\n",
        "\n",
        "real_train_dataset = tf.data.TFRecordDataset(path_real_train_dataset).map(parse_function)\n",
        "real_valid_dataset = tf.data.TFRecordDataset(path_real_train_dataset).map(parse_function)\n",
        "real_test_dataset = tf.data.TFRecordDataset(path_real_train_dataset).map(parse_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL05931KjzUs",
        "outputId": "cff7dc68-f8e4-426e-fed0-eb859980bdda"
      },
      "source": [
        "for a,b,c in valid_dataset.take(3):\n",
        "  print(a,b,c)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[    1 10205 11192 11307 11308 11407 11505 12008 12906 12910 13005 13008\n",
            " 13010 13108 13208 13607 14106 14206 14311 14707 14711 15508 15709 15713\n",
            " 15813 15907 16008 16708 17088 17111 17309 17511 17610 18106 18509 18512\n",
            " 18908 19808 19907 20108 20310 20807 20905 21107 21308 21609 22112 22508\n",
            " 22608 22615 22706 22713 22715 23109 23210 23316 24211 24218 24311 24409\n",
            " 24416 24509 24512 24516 24912 24916 25209 25510 25609 26012 26019 26112\n",
            " 26214 26611 27010 27111 27151 27312 28112 28211 28412 28811 28816 28912\n",
            " 29913 30015 30508 30911 31010 31110 31318 31516 32111 32309 32515 32613\n",
            " 32712 32812 32968 33018 33119 33216 33220 33814 33868 33913 34013 34110\n",
            " 34118 34315 34514 34614 34722 34911 35314 35414 35615 35714 35813 36216\n",
            " 36316 36419 36614 36712 37116 37215 37416 37814 38415 38513 38670 38719\n",
            " 38769 38917 39017 39223 39570 39615 39621 39824 40216 40316 40613 40719\n",
            " 40819 40869 40919 41018 41023 41117 41124 41169 41215 41520 41717 42018\n",
            " 42216 42315 42414 42819 42825 42917 42925 43017 43321 43370 43420 43518\n",
            " 44017 44117 44216 44221 44271 44321 44620 44719 45016 45116 45122 45171\n",
            " 45221 45419 45618 45716 45818 45919 46023 46073 46220 46271 46421 46622\n",
            " 46718 46817 46917 47121 47171 47220 47323 47373 47419 47520 48172 48221\n",
            " 48327 48373 48423 48473 48520 48618 48718 49072 49122 49172 49221 49274\n",
            " 49323 49373 49422 49473 49874 49924 49973 50023 50072 50174 50224 50274\n",
            " 50320 50373 50421 50472 50679 50729 50774 50781 50824 50874 50924 51075\n",
            " 51125 51225 51274 51324 51373 51419 51675 51726 51823 52125 52174 52224\n",
            " 52619 52720 53025 53075 53125 53221 53879 53927 53980 54421 54724 54824\n",
            " 55320 55419 55731 55831 56123 56824 56923 57022 57121 57531 57632 58225\n",
            " 58626 58724 58824 58923 59326 59624 59723 59823 60129 60427 60525 60626\n",
            " 61425 61524 61624 62228 62328 63128 63214 63226 63325 63425 65027 65127\n",
            " 65836 65935 67336 67529 67636 67737 67747 67834 68528 70131 70331 71131\n",
            " 71229 71933 72031 72932 73031 74171 74430 74638 74732 74833 75536 77240\n",
            " 77338 77373 77438 78132 78235 78934 79041 79141 79834 79932 80033 80139\n",
            " 80737 81635 81734 81834 83436 83537 83744 85843 85979 86527 88343 88441\n",
            " 88541 88945 89242 90123 90144 90243 90342 91341 91945 92045 92943 93044\n",
            " 93143 94142 96347 97747     2], shape=(365,), dtype=int64) tf.Tensor(\n",
            "[    0    20     0   743    15    20    51   236     2   247   144    33\n",
            "    11  2366    47     1  2225    63     1    11   394    13    21    40\n",
            "     7  3788   123    15     0    23     2    18     1    14    78    47\n",
            "    12    63    55    13   156    13    24    52    95   354    78    19\n",
            "   509   323    61    10    16   418    34    18   394    21    27   762\n",
            "  3598    34    23   253    81    14    26    18     1    67    21    10\n",
            "     1    24  3171   260    11    10    43    18    12   547    13    55\n",
            "   115    17    22   158    41    12    77    12    21    53    13    15\n",
            "   838    54    91    12  2088    28   191    15    91   155    37    22\n",
            "   189    17   281    22    23    16    22    17    89   226    40    12\n",
            "    75    15    45    65    45    32   115    15   395   118   241   196\n",
            "    17    40    21    23    76    53    21    21   529    70    75    11\n",
            "    11    62    25    44  1485    26   185    19    12    11    35    18\n",
            "    49    31   201   545 10000   581  1400   132    53    59    11    27\n",
            "   164    67    34   773   770   243   467   124   110     4   760   817\n",
            "   218    42   402   124   243    56   889   314    10    18    25    10\n",
            "   177   485    67    29    19    36    21    19   627   152    25    87\n",
            "    41    10    22    42   667   559    68   498   615   147    75    82\n",
            "   165    71    63    14    47   155   352   169    13   411   509   139\n",
            "   840    34   144    14   274   157    31    29   516   327    27   516\n",
            "   272   153   528   214    13    15    31    17    15  1935  2563   795\n",
            "    52    16  6502  4498   806    13  1447  1367   683    20    27    19\n",
            "   114    37   164    27    15    19    73    40   136  4641  1113    16\n",
            "    50   224   100    65    12    44   187    34    77    93   214    50\n",
            "   274   495   117    87    13    11    27  1088   821   127   378    84\n",
            "   246    68    13    12  3321   940     9    16    17    14    22    31\n",
            "    63    38    10   118    94    10    13    26   111    47    39   775\n",
            "  1243    13   360    32    12    19  5824  1916    80   102    26    31\n",
            "    23   239   201    32   165    36    82    15    10    12    78   258\n",
            "    80    16    47    22   920  1453   506    20  3722  1408    12    65\n",
            "    30    16    17    16     0], shape=(365,), dtype=int64) tf.Tensor([ 1 19 16  7  9 16 11 17  6 17 10  2], shape=(12,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[    1 10205 10402 10530 11007 11208 11307 11347 11508 11607 12008 12108\n",
            " 12708 12906 12910 12911 13004 13008 13009 13111 13309 13607 14106 14311\n",
            " 14412 14711 14805 14811 15508 15611 15710 15713 15809 15813 15907 15909\n",
            " 15911 16701 16904 16906 17004 17006 17111 17312 17511 17612 17820 18314\n",
            " 18512 18514 18516 18608 18707 18807 19111 19712 19918 20112 21210 21315\n",
            " 21513 21614 21911 22011 22512 22610 22717 22817 22911 22965 23111 23211\n",
            " 23264 23316 24013 24108 24113 24214 24310 24313 24413 24512 24618 24912\n",
            " 25012 25308 25316 25414 25515 25715 25811 25814 25910 27110 27117 27215\n",
            " 27316 27517 27711 27812 28214 28314 28419 28519 28820 28911 28920 29414\n",
            " 29917 30015 30115 30215 30319 31718 31818 31918 32617 32709 32717 33014\n",
            " 33413 33817 34419 34815 34915 35006 35223 35523 35619 35917 36616 37024\n",
            " 37124 37718 37818 38319 38419 38519 38727 38827 39020 39120 39317 39797\n",
            " 40121 40220 40327 41118 41219 41622 41923 42327 42920 43021 43126 43225\n",
            " 43324 43424 44128 44375 44722 44822 45830 45923 45931 46123 46224 46828\n",
            " 49522 49726 49927 49977 50024 50133 51225 51325 51731 51826 51974 52425\n",
            " 53026 53125 53827 54024 54432 54827 55825 55834 55925 56030 57921 58736\n",
            " 58834 58935 59930 60139 60537 60637 61536 61831 62929 65739 65937 71640\n",
            " 71740 71840 73441 73542 74440 75036 79240 81148 81849 84750 84850 84949\n",
            " 90452 90552 91948     2], shape=(220,), dtype=int64) tf.Tensor(\n",
            "[    0   424     0     1    70    75    79     2    81   107   850    67\n",
            "     5     4   171    19    63    82    33    54    30    82   293   982\n",
            "    32   173    86     4    30   156    65   459   443    36   374    39\n",
            "    46     5    32  1337    17    81   746    36  3687   129    83    24\n",
            "   189    26   285    25  2627   109   245    91    52    70    27   294\n",
            "   683    42   788    40    20    31    23   127    80    12   373    25\n",
            "    25    48    30    43    21   125    47  1797   122    37    37   304\n",
            "    40    29    68  1871   130    50    29    90   179    42  1123   202\n",
            "   126    43   439    38  1513   134   118    33  2688   112   221    28\n",
            "    50   686    73   125    45    32   794    50    43    19    22   311\n",
            "    66    43    80   760    85    25    51    26    81    52    32   249\n",
            "    21    77    22   274   179    24  2809   378   239    33    69    22\n",
            "   287    71   101  1188   121    29   123    27   252    47    41    24\n",
            "    22    23   101    49   249    44  6893    32  1114   141    26    27\n",
            "    26    20    35    28    24    48   238    68   487    34    31    21\n",
            "    83    38    20    50    52    29   205    45    66    43    20    39\n",
            "   182    26    21    25 10000  2516    23    22    29    26    24  2280\n",
            "   859    34  5339  1805    66    27    20    32    38   652   250    44\n",
            "   642   237    43     0], shape=(220,), dtype=int64) tf.Tensor([ 1  7 19  8  7 11 13  5  3 18  2], shape=(11,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[    1 10205 10305 11007 11107 11207 11208 11505 11508 11970 12008 12107\n",
            " 12108 12906 12910 12911 13004 13008 13010 13104 13109 13306 13607 13806\n",
            " 14110 14311 14707 14711 14811 15508 15607 15706 15709 15809 16007 16060\n",
            " 16606 16913 17006 17107 17312 17405 17460 17507 17511 17813 17821 18011\n",
            " 18105 18109 18307 18314 18415 18612 18707 18714 18907 18908 19313 19730\n",
            " 19808 19812 19907 19910 20010 20109 20112 20205 20708 20796 20810 21114\n",
            " 21157 21211 21308 21513 21609 21613 21708 21713 22315 22509 22608 22611\n",
            " 22706 22817 23314 23412 23414 23514 24010 24013 24108 24409 24512 24609\n",
            " 25115 25215 25713 26013 26113 26810 26864 27363 27520 27616 27914 28264\n",
            " 28313 28513 28610 28613 29495 30317 30321 30364 30411 30421 30915 31216\n",
            " 31265 31592 31715 31811 31849 31882 32117 32218 32449 32483 32615 32811\n",
            " 33019 33612 33818 34514 34815 34820 34920 35166 35414 35512 35521 35619\n",
            " 36066 36235 36316 36366 36416 36617 37216 37266 37312 37317 37410 37415\n",
            " 37421 38117 38167 38217 38617 39020 40228 40724 40820 40921 41722 42020\n",
            " 42070 42316 42323 42871 42921 43221 43370 43523 43771 43821 43872 44117\n",
            " 44215 44270 44321 44921 45235 46722 46872 47723 47773 48624 48674 48724\n",
            " 49218 49326 49527 49628 50122 51019 51331 51429 51924 52820 53132 53232\n",
            " 53333 53725 53825 54628 54730 54830 55426 56427 56528 57037 57137 57921\n",
            " 58826 59722 59822 60528 60627 60727 61523 61624 62428 62528 62628 63126\n",
            " 63324 63426 63526 64140 64335 64635 64831 64933 65131 66037 66137 66236\n",
            " 68433 69230 70231 70329 70729 72032 72133 72532 73833 74332 74433 75140\n",
            " 76044 76134 76234 76334 78847 79736 80736 82537 85641 85741 87442 87542\n",
            " 88544 92479 94259     2], shape=(268,), dtype=int64) tf.Tensor(\n",
            "[    0    34   212  1997    85     0    36    33    35    13 10000    21\n",
            "   766    47  1496    47     1   592    69    36     8    34    92    66\n",
            "    49    57    29   774    29     2    95   181     1    66    29    25\n",
            "   193    23    26    47    22    40    48    52   501    36    31    22\n",
            "    58    38    27  1479   137   106    29   123    24    33    58     2\n",
            "    22    34   115   111    24    40    53    25    47   112    29   311\n",
            "    24    32    24    88    66   216   151   129   141   280    75    57\n",
            "    30    43    39    76   615    85    29    89    48   242    45    25\n",
            "   571    51   105    25    51    72    36    29    76    36   134    85\n",
            "    16   133    62    33   118    19   101    31    31    25    22    27\n",
            "    20    22    24   158   135    54   340    86    99    31    58    25\n",
            "    30    43    78    54    53   391    78    27   126    49   130   161\n",
            "    33    23    66    82    21   165  1149   345    30   589   146    27\n",
            "   107  1477   556    60    96    58    35    22   861   117    46    81\n",
            "   111   132    29   409   172    38    23   123   367   169    27    83\n",
            "    23   273    78    57    19    31    31   154    74   376   203    41\n",
            "    77    28    42    26    21   123    31    71   167    51   155   137\n",
            "    26   360    99    40   219   152    29   113    53   188    49   119\n",
            "    76   150    28    49   277    63   193    35  1765   520    38    30\n",
            "   177   168    41    76    39    35    82    28    69   167   296    55\n",
            "    31    26    48    19    24    81    22    87    55   385   165    23\n",
            "   109  1441   487    37    27    32    46    34    81    33   294   104\n",
            "    50    31    24     0], shape=(268,), dtype=int64) tf.Tensor([ 1 11 17  8 21  6  7  6  6  6 10  2], shape=(12,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7yvNBaFTFLe",
        "outputId": "dcd0de82-ce2f-4eb3-ef76-104d7a2ba2bc"
      },
      "source": [
        "for data in real_dataset:\n",
        "  size_dataset+=1\n",
        "print(f'Size of dataset : {size_dataset}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of dataset : 4361858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1tjOVQryYtj"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "size_train_dataset = 3041294\n",
        "NUM_BATCHS = int(size_train_dataset/BATCH_SIZE)\n",
        "real_train_batchs = (real_train_dataset\n",
        "                     .shuffle(4000000)\n",
        "                     .padded_batch(BATCH_SIZE)\n",
        "                     .prefetch(tf.data.AUTOTUNE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "wjsdW8wJfNma",
        "outputId": "59d7c4c1-5443-40e3-bcd1-50afeba2f192"
      },
      "source": [
        "import time\n",
        "\n",
        "epoch = 0\n",
        "size_smallset = size_dataset / num_shards\n",
        "NUM_BATCHS = int(size_smallset/BATCH_SIZE)\n",
        "\n",
        "while True:\n",
        "    start = time.time()\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "\n",
        "    for index in range(num_shards-2):\n",
        "      train_batchs = (real_dataset\n",
        "                      .shard(num_shards=num_shards, index = index+2)\n",
        "                      .padded_batch(BATCH_SIZE)\n",
        "                      .prefetch(tf.data.AUTOTUNE))\n",
        "      \n",
        "      for batch, (input, intensity, target) in enumerate(train_batchs):\n",
        "          train_step_finetuning(input, intensity, target)\n",
        "\n",
        "          print('\\r',f'Epoch {epoch + 1} | shard {index+1}/{num_shards-2} | batch {batch+1}/{NUM_BATCHS} Loss {train_loss.result():.3f} Accuracy {train_accuracy.result():.4f}',end='')\n",
        "  \n",
        "    print('\\r',f'Epoch {epoch + 1} : Time {time.time() - start:.2f}s')\n",
        "  \n",
        "    ckpt_path_finetuning = ckpt_manager_finetuning.save()\n",
        "    print('\\r', f'Saving checkpoint for epoch {epoch + 1} at {ckpt_path_finetuning}')\n",
        "\n",
        "    print(f'\\tTrain | Loss {train_loss.result():.3f}, Accuracy {train_accuracy.result():.3f}')\n",
        "    valid_loss, valid_accuracy = evaluate_aminoacid_level_finetuning(valid_dataset)\n",
        "    print(f'\\tValid | Loss {valid_loss:.3f}, Accuracy {valid_accuracy:.3f}')\n",
        "\n",
        "    epoch+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Epoch 1 : Time 18961.29s\n",
            " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-1\n",
            "\tTrain | Loss 2.175, Accuracy 0.321\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Decoder2.call at 0x7fe052048440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Decoder2.call at 0x7fe052048440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\tValid | Loss 1.862, Accuracy 0.414\n",
            " Epoch 2 | shard 25/200 | batch 47/84 Loss 1.978 Accuracy 0.3796"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6988bafd17ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                       .prefetch(tf.data.AUTOTUNE))\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batchs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m           \u001b[0mtrain_step_finetuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2723\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2724\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GgSacO8CnVX",
        "outputId": "e7fa710b-caf0-40a2-e53a-bcb15b054f06"
      },
      "source": [
        "ckpt_path_finetuning = ckpt_manager_finetuning.save()\n",
        "print('\\r', f'Saving checkpoint for epoch {epoch + 1} at {ckpt_path_finetuning}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI3OhoyDCyuR"
      },
      "source": [
        "'''\n",
        "Epoch 1 : Time 26541.71s\n",
        "\tTrain | Loss 2.183, Accuracy 0.319\n",
        "\tValid | Loss 1.849, Accuracy 0.419\n",
        " Epoch 2 : Time 26385.37s\n",
        "\tTrain | Loss 1.912, Accuracy 0.402\n",
        "\tValid | Loss 1.653, Accuracy 0.483\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxMheUlku-c9"
      },
      "source": [
        "def evaluate_peptide_level_finetuning(dataset, max_length = 50):\n",
        "    cnt_total =0\n",
        "    cnt_correct = 0\n",
        "    for mz, intensity, sequence in dataset:\n",
        "        cnt_total+=1\n",
        "        if(cnt_total%10 == 0):\n",
        "            print(cnt_total, cnt_correct/(cnt_total-1))\n",
        "\n",
        "        encoder_input = tf.convert_to_tensor([mz])\n",
        "        start, end = 1,2\n",
        "        output = tf.convert_to_tensor([start],dtype=tf.int64)\n",
        "        output = tf.expand_dims(output, 0)\n",
        "\n",
        "        for i in range(max_length):\n",
        "            enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input, output)\n",
        "            encoder1 = pretrained_transformer.encoder\n",
        "            encoder1_output = encoder1(input, False, enc_padding_mask)\n",
        "\n",
        "            predictions, _ = modified_transformer(encoder1_output,\n",
        "                                                  intensity,\n",
        "                                                  output,\n",
        "                                                  False,\n",
        "                                                  enc_padding_mask,\n",
        "                                                  combined_mask,\n",
        "                                                  dec_padding_mask)\n",
        "             \n",
        "            # select the last word from the seq_len dimension\n",
        "            predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "            predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "            # concatentate the predicted_id to the output which is given to the decoder\n",
        "            # as its input.\n",
        "            output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "            # return the result if the predicted_id is equal to the end token\n",
        "            if predicted_id == end:\n",
        "                if output.shape[1]==sequence.shape[0] and tf.reduce_all(output[0] == sequence):\n",
        "                    cnt_correct+=1\n",
        "                break\n",
        "\n",
        "    return cnt_correct/cnt_total\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlHT8fiUDQKF"
      },
      "source": [
        "path_test_data='/content/drive/MyDrive/translateMS/data/real_preprocessed_test_data.tfrecords'\n",
        "\n",
        "test_dataset = tf.data.TFRecordDataset(path_test_data).map(parse_function).shuffle(10000).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "AwqVgZJmDfjZ",
        "outputId": "0220e03f-6442-481f-df16-a4a38e44bac4"
      },
      "source": [
        "accuracy_test_data = evaluate_peptide_level_finetuning(test_dataset.take(200))\n",
        "print(f'Accuracy of test data for peptide level : {accuracy_test_data:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-0bb182f3b6ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_peptide_level_finetuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy of test data for peptide level : {accuracy_test_data:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-185c054c7018>\u001b[0m in \u001b[0;36mevaluate_peptide_level_finetuning\u001b[0;34m(dataset, max_length)\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                   \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                   \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                                                   dec_padding_mask)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# select the last word from the seq_len dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-4c08d26a23e6>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input, intensity, target, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m     44\u001b[0m   def call(self, input, intensity, target, training, enc_padding_mask,\n\u001b[1;32m     45\u001b[0m            look_ahead_mask, dec_padding_mask):\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0;31m# dec_output.shape == (batch_size, tar_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-4c08d26a23e6>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, intensity, training, mask)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# adding embedding and position encoding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mintensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintensity\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, intensity_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mintensity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    521\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6897\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6898\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: required broadcastable shapes at loc(unknown) [Op:AddV2]"
          ]
        }
      ]
    }
  ]
}