{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "translateMS_finetuning_plus_embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKB1DavlxRBs",
        "outputId": "3a21f704-ccbe-4386-e928-f9d9bc7621dc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct  4 04:51:34 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSyILgafxv2U"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def get_angles(position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    #tf.newaxis : expand dimensions\n",
        "    angle_rads = get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # list[<start>:<end>:<step>] even indices '0::2'\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # list[<start>:<end>:<step>] odd indices '1::2'\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    angle_rads = np.zeros(angle_rads.shape)\n",
        "    angle_rads[:, 0::2] = sines\n",
        "    angle_rads[:, 1::2] = cosines\n",
        "    pos_encoding = tf.constant(angle_rads)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return look_ahead_mask\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead)\n",
        "    but it must be broadcastable for addition.\n",
        "    Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    Returns:\n",
        "    output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, self.d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               target_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
        "\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, dropout_rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights\n",
        "\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size,target_vocab_size,\n",
        "               positional_encoding_input,positional_encoding_target,\n",
        "               dropout_rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                             input_vocab_size,positional_encoding_input, dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, positional_encoding_target, dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, input, target, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(input, training, enc_padding_mask)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        target, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return enc_output, dec_output, final_output, attention_weights\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LutQiUAsx30T"
      },
      "source": [
        "class Encoder2(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               intensity_vocab_size, dropout_rate=0.1):\n",
        "    super(Encoder2, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(intensity_vocab_size, self.d_model)\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x, intensity, training, mask):\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    intensity = self.embedding(intensity)  # (batch_size, intensity_seq_len, d_model)\n",
        "    x += intensity\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "\n",
        "class Decoder2(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "\n",
        "    super(Decoder2, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, dropout_rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights\n",
        "\n",
        "class ModifiedTransformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               intensity_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "      super(ModifiedTransformer, self).__init__()\n",
        "\n",
        "      self.encoder = Encoder2(num_layers, d_model, num_heads, dff,\n",
        "                              intensity_vocab_size, dropout_rate)\n",
        "\n",
        "      self.decoder = Decoder2(num_layers, d_model, num_heads,\n",
        "                              dff, dropout_rate)\n",
        "\n",
        "      self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, input, intensity, target, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "      enc_output = self.encoder(input, intensity, training, enc_padding_mask)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "      # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "      dec_output, attention_weights = self.decoder(target, \n",
        "                                                   enc_output,\n",
        "                                                   training,\n",
        "                                                   look_ahead_mask,\n",
        "                                                   dec_padding_mask)\n",
        "\n",
        "      final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "      return final_output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4dMP7VIx4Zq"
      },
      "source": [
        "def create_masks(input, target):\n",
        "    # Encoder padding mask\n",
        "    enc_padding_mask = create_padding_mask(input)\n",
        "    # Used in the 2nd attention block in the decoder.\n",
        "    # This padding mask is used to mask the encoder outputs.\n",
        "    dec_padding_mask = create_padding_mask(input)\n",
        "    # Used in the 1st attention block in the decoder.\n",
        "    # It is used to pad and mask future tokens in the input received by\n",
        "    # the decoder.\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(target)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(target)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
        "\n",
        "\n",
        "'''\n",
        "d_model : input(embedding), ouput 차원\n",
        "num_layers : 인코더, 디코더 층\n",
        "num_heads : 멀티헤드 수\n",
        "d_ff : feedforward 차원 \n",
        "'''\n",
        "D_MODEL = 128\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 8\n",
        "DFF = 512\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEz4fBsQyANz"
      },
      "source": [
        "def evaluate_aminoacid_level_finetuning(dataset):\n",
        "    batch_size = 32\n",
        "    num_batchs = 0\n",
        "    accuracy = 0\n",
        "    loss = 0\n",
        "\n",
        "    dataset_batchs = dataset.padded_batch(batch_size = batch_size, drop_remainder=True)\n",
        "\n",
        "    for batch, (input, intensity, target) in enumerate(dataset_batchs):\n",
        "        num_batchs = batch+1\n",
        "        target_input = target[:, :-1]\n",
        "        target_real = target[:, 1:]\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input, target_input)\n",
        "\n",
        "        encoder1_output, decoder1_output, _, _ = \\\n",
        "            pretrained_transformer(input,\n",
        "                                   target_input,\n",
        "                                   False,\n",
        "                                   enc_padding_mask,\n",
        "                                   combined_mask,\n",
        "                                   dec_padding_mask)\n",
        "\n",
        "        predictions, _ = modified_transformer(encoder1_output,\n",
        "                                              intensity,\n",
        "                                              decoder1_output,\n",
        "                                              False,\n",
        "                                              enc_padding_mask,\n",
        "                                              combined_mask,\n",
        "                                              dec_padding_mask)\n",
        "\n",
        "        loss += loss_function(target_real, predictions)\n",
        "        accuracy += accuracy_function(target_real, predictions)\n",
        "\n",
        "    return loss/num_batchs, accuracy/num_batchs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3RMFrgKyEwg"
      },
      "source": [
        "pretrained_transformer = Transformer(\n",
        "    num_layers=NUM_LAYERS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dff=DFF,\n",
        "    input_vocab_size=600000,\n",
        "    target_vocab_size=30,\n",
        "    positional_encoding_input = 2000,\n",
        "    positional_encoding_target = 50,\n",
        "    dropout_rate=DROPOUT_RATE)\n",
        "\n",
        "modified_transformer = ModifiedTransformer(\n",
        "    num_layers=NUM_LAYERS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dff=DFF,\n",
        "    intensity_vocab_size=12000,\n",
        "    target_vocab_size=30,\n",
        "    dropout_rate=DROPOUT_RATE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU2su-PtyGA5",
        "outputId": "62884cd6-8ab2-4cb0-ad77-621e1053e9f0"
      },
      "source": [
        "#load pretraining checkpoint\n",
        "\n",
        "ckpt_path_pretraining = '/content/drive/MyDrive/translateMS/checkpoints/pretraining_128_2_8_512_0.2/ckpt-16'\n",
        "\n",
        "ckpt_pretraining = tf.train.Checkpoint(transformer=pretrained_transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_pretraining.restore(ckpt_path_pretraining)\n",
        "print('Checkpoint restored!!')\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "#if ckpt_manager.latest_checkpoint:\n",
        "#    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "#    print('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint restored!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7723qrlyJrm",
        "outputId": "7082c131-6e34-4b96-ad82-0246293e2c3c"
      },
      "source": [
        "checkpoint_path_finetuning = \"/content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2\"\n",
        "\n",
        "ckpt_finetuning = tf.train.Checkpoint(transformer=modified_transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager_finetuning = tf.train.CheckpointManager(ckpt_finetuning, checkpoint_path_finetuning, max_to_keep=10)\n",
        "\n",
        "#ckpt_finetuning.restore(checkpoint_path_finetuning)\n",
        "\n",
        "if ckpt_manager_finetuning.latest_checkpoint:\n",
        "    print(ckpt_manager_finetuning.latest_checkpoint)\n",
        "    ckpt_finetuning.restore(ckpt_manager_finetuning.latest_checkpoint)\n",
        "    print('Latest checkpoint restored!!')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-51\n",
            "Latest checkpoint restored!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkhNeDXXyMVh"
      },
      "source": [
        "train_step_signature_finetuning = [\n",
        "  tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "  tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "  tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature_finetuning)\n",
        "def train_step_finetuning(input, intensity, target):\n",
        "\n",
        "    target_input = target[:, :-1]\n",
        "    target_real = target[:, 1:]\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input, target_input)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        #return : enc_output, dec_output, final_output, attention_weights\n",
        "        encoder1_output, decoder1_output, _, _ = \\\n",
        "            pretrained_transformer(input,\n",
        "                                   target_input,\n",
        "                                   False,\n",
        "                                   enc_padding_mask,\n",
        "                                   combined_mask,\n",
        "                                   dec_padding_mask)\n",
        "\n",
        "        predictions, _ = modified_transformer(encoder1_output,\n",
        "                                             intensity,\n",
        "                                             decoder1_output,\n",
        "                                             True,\n",
        "                                             enc_padding_mask,\n",
        "                                             combined_mask,\n",
        "                                             dec_padding_mask)\n",
        "\n",
        "        loss = loss_function(target_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, modified_transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, modified_transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy_function(target_real, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah_dJZH6yN40"
      },
      "source": [
        "feature_description = {\n",
        "            'sequence': tf.io.VarLenFeature(tf.int64),\n",
        "            'intensity': tf.io.VarLenFeature(tf.int64),\n",
        "            'mz': tf.io.VarLenFeature(tf.int64),\n",
        "            }\n",
        "\n",
        "def parse_function(example_proto):\n",
        "    parsed_example = tf.io.parse_single_example(example_proto,feature_description)\n",
        "    mz = parsed_example['mz'].values\n",
        "    intensity = parsed_example['intensity'].values\n",
        "    sequence = parsed_example['sequence'].values\n",
        "    return mz, intensity, sequence\n",
        "\n",
        "path_real_train_dataset='/content/drive/MyDrive/translateMS/data/real_preprocessed_train_data.tfrecords'\n",
        "path_real_valid_dataset='/content/drive/MyDrive/translateMS/data/real_preprocessed_valid_data.tfrecords'\n",
        "path_real_test_dataset='/content/drive/MyDrive/translateMS/data/real_preprocessed_test_data.tfrecords'\n",
        "\n",
        "\n",
        "size_dataset = 0\n",
        "\n",
        "'''\n",
        "number of data : 6503421\n",
        "number of  data/real_preprocessed_train_data  :  3041294\n",
        "number of  data/real_preprocessed_valid_data  :  380190\n",
        "number of  data/real_preprocessed_test_data  :  390013\n",
        "\n",
        "number of peptide in train dataset : 85058\n",
        "number of peptide in valid dataset : 10660\n",
        "number of peptide in test dataset : 10684\n",
        "number of total peptide : 106402\n",
        "\n",
        "'''\n",
        "#train데이터는 절반 사용\n",
        "real_train_dataset = tf.data.TFRecordDataset(path_real_train_dataset).map(parse_function).shard(num_shards=2, index=0)\n",
        "\n",
        "#valid, test data는 1/10 사용\n",
        "real_valid_dataset = tf.data.TFRecordDataset(path_real_valid_dataset).map(parse_function).shard(num_shards=10, index=0)\n",
        "real_test_dataset = tf.data.TFRecordDataset(path_real_test_dataset).map(parse_function).shard(num_shards=10, index=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "asmnw1EZbHHI",
        "outputId": "946ed970-88cd-448e-a2bc-7b7514563489"
      },
      "source": [
        "cnt=0\n",
        "for i in real_valid_dataset:\n",
        "  cnt+=1\n",
        "print(cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1cb3950c5383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreal_valid_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mcnt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2723\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2724\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHCd3QeByRyM"
      },
      "source": [
        "BATCH_SIZE = 48\n",
        "size_train_dataset = 3041294//2\n",
        "NUM_BATCHS = int(size_train_dataset/BATCH_SIZE)\n",
        "real_train_batchs = (real_train_dataset\n",
        "                     .shuffle(4000000)\n",
        "                     .padded_batch(BATCH_SIZE)\n",
        "                     .prefetch(tf.data.AUTOTUNE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB7gRfZv40XN",
        "outputId": "817d1c47-ee97-469b-9662-5f9f33392b9f"
      },
      "source": [
        "valid_loss, valid_accuracy = evaluate_aminoacid_level_finetuning(real_valid_dataset.take(64))\n",
        "print(f'\\tValid | Loss {valid_loss:.3f}, Accuracy {valid_accuracy:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tValid | Loss 0.722, Accuracy 0.804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "C92qKywkySg1",
        "outputId": "1dfab441-f353-420e-ee81-5396e0391a71"
      },
      "source": [
        "import time\n",
        "\n",
        "epoch = 0\n",
        "\n",
        "while True:\n",
        "    start = time.time()\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "\n",
        "    for batch, (input, intensity, target) in enumerate(real_train_batchs):\n",
        "        train_step_finetuning(input, intensity, target)\n",
        "\n",
        "        print('\\r',f'Epoch {epoch + 1} | batch {batch+1}/{NUM_BATCHS} Loss {train_loss.result():.3f} Accuracy {train_accuracy.result():.4f}',end='')\n",
        "\n",
        "    print('\\r',f'Epoch {epoch + 1} : Time {time.time() - start:.2f}s')\n",
        "  \n",
        "    print(f'\\tTrain | Loss {train_loss.result():.3f}, Accuracy {train_accuracy.result():.3f}')\n",
        "    valid_loss, valid_accuracy = evaluate_aminoacid_level_finetuning(real_valid_dataset)\n",
        "    print(f'\\tValid | Loss {valid_loss:.3f}, Accuracy {valid_accuracy:.3f}')\n",
        "\n",
        "    ckpt_path_finetuning = ckpt_manager_finetuning.save()\n",
        "    print('\\r', f'Saving checkpoint for epoch {epoch + 1} at {ckpt_path_finetuning}')\n",
        "\n",
        "    epoch+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Epoch 1 | batch 22823/31680 Loss 1.335 Accuracy 0.5798"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaXXgCHSOfOB"
      },
      "source": [
        "'''\n",
        "Epoch 1 : Time 6657.42s\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-1\n",
        "\tTrain | Loss 2.242, Accuracy 0.291\n",
        "\tValid | Loss 1.883, Accuracy 0.392\n",
        " Epoch 2 : Time 6649.44s\n",
        " Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-2\n",
        "\tTrain | Loss 1.961, Accuracy 0.371\n",
        "\tValid | Loss 1.874, Accuracy 0.399\n",
        " Epoch 3 : Time 6645.95s\n",
        " Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-3\n",
        "\tTrain | Loss 1.834, Accuracy 0.414\n",
        "\tValid | Loss 1.650, Accuracy 0.472\n",
        " Epoch 4 : Time 6598.67s\n",
        " Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-4\n",
        "\tTrain | Loss 1.757, Accuracy 0.440\n",
        "\tValid | Loss 1.648, Accuracy 0.477\n",
        " Epoch 1 : Time 6608.44s\n",
        "\tTrain | Loss 1.704, Accuracy 0.458\n",
        "\tValid | Loss 1.616, Accuracy 0.490\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-5\n",
        " Epoch 2 : Time 6565.93s\n",
        "\tTrain | Loss 1.664, Accuracy 0.472\n",
        "\tValid | Loss 1.615, Accuracy 0.493\n",
        " Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-6\n",
        " Epoch 3 : Time 6557.52s\n",
        "\tTrain | Loss 1.632, Accuracy 0.483\n",
        "\tValid | Loss 1.501, Accuracy 0.532\n",
        " Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-7\n",
        " Epoch 4 : Time 6565.39s\n",
        "\tTrain | Loss 1.605, Accuracy 0.492\n",
        "\tValid | Loss 1.446, Accuracy 0.548\n",
        " Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-8\n",
        " Epoch 5 : Time 6534.36s\n",
        "\tTrain | Loss 1.582, Accuracy 0.500\n",
        "\tValid | Loss 1.449, Accuracy 0.550\n",
        " Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-9\n",
        " Epoch 6 : Time 6530.70s\n",
        "\tTrain | Loss 1.562, Accuracy 0.506\n",
        "\tValid | Loss 1.379, Accuracy 0.573\n",
        " Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-10\n",
        " Epoch 7 : Time 6542.19s\n",
        "\tTrain | Loss 1.545, Accuracy 0.512\n",
        "\tValid | Loss 1.474, Accuracy 0.542\n",
        " Saving checkpoint for epoch 7 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-11\n",
        "  Epoch 1 : Time 6350.71s\n",
        "\tTrain | Loss 1.517, Accuracy 0.521\n",
        "\tValid | Loss 1.408, Accuracy 0.566\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-13\n",
        " Epoch 2 : Time 6336.78s\n",
        "\tTrain | Loss 1.504, Accuracy 0.526\n",
        "\tValid | Loss 1.303, Accuracy 0.598\n",
        " Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-14\n",
        " Epoch 3 : Time 6338.12s\n",
        "\tTrain | Loss 1.493, Accuracy 0.529\n",
        "\tValid | Loss 1.341, Accuracy 0.586\n",
        " Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-15\n",
        " Epoch 4 : Time 6334.88s\n",
        "\tTrain | Loss 1.482, Accuracy 0.532\n",
        "\tValid | Loss 1.326, Accuracy 0.591\n",
        " Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-16\n",
        " Epoch 5 : Time 6333.28s\n",
        "\tTrain | Loss 1.473, Accuracy 0.535\n",
        "\tValid | Loss 1.338, Accuracy 0.588\n",
        " Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-17\n",
        " Epoch 6 : Time 6334.97s\n",
        "\tTrain | Loss 1.465, Accuracy 0.538\n",
        "\tValid | Loss 1.295, Accuracy 0.599\n",
        " Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-18\n",
        " Epoch 7 : Time 6334.57s\n",
        "\tTrain | Loss 1.456, Accuracy 0.541\n",
        "\tValid | Loss 1.299, Accuracy 0.599\n",
        " Saving checkpoint for epoch 7 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-19\n",
        " Epoch 8 : Time 6341.37s\n",
        "\tTrain | Loss 1.449, Accuracy 0.543\n",
        "\tValid | Loss 1.268, Accuracy 0.611\n",
        " Saving checkpoint for epoch 8 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-20\n",
        "  Epoch 1 : Time 6422.34s\n",
        "\tTrain | Loss 1.442, Accuracy 0.545\n",
        "\tValid | Loss 1.279, Accuracy 0.607\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-21\n",
        " Epoch 2 : Time 6413.57s\n",
        "\tTrain | Loss 1.435, Accuracy 0.548\n",
        "\tValid | Loss 1.305, Accuracy 0.601\n",
        " Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-22\n",
        " Epoch 3 : Time 6402.30s\n",
        "\tTrain | Loss 1.429, Accuracy 0.549\n",
        "\tValid | Loss 1.244, Accuracy 0.620\n",
        " Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-23\n",
        " Epoch 4 : Time 6421.73s\n",
        "\tTrain | Loss 1.424, Accuracy 0.551\n",
        "\tValid | Loss 1.282, Accuracy 0.606\n",
        " Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-24\n",
        "  Epoch 1 : Time 6387.95s\n",
        "\tTrain | Loss 1.419, Accuracy 0.553\n",
        "\tValid | Loss 1.237, Accuracy 0.617\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-25\n",
        " Epoch 2 : Time 6356.98s\n",
        "\tTrain | Loss 1.413, Accuracy 0.555\n",
        "\tValid | Loss 1.224, Accuracy 0.624\n",
        " Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-26\n",
        " Epoch 3 : Time 6358.52s\n",
        "\tTrain | Loss 1.408, Accuracy 0.556\n",
        "\tValid | Loss 1.304, Accuracy 0.599\n",
        " Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-27\n",
        " Epoch 4 : Time 6359.08s\n",
        "\tTrain | Loss 1.404, Accuracy 0.558\n",
        "\tValid | Loss 1.220, Accuracy 0.624\n",
        " Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-28\n",
        " Epoch 5 : Time 6392.57s\n",
        "\tTrain | Loss 1.400, Accuracy 0.559\n",
        "\tValid | Loss 1.223, Accuracy 0.626\n",
        " Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-29\n",
        " Epoch 1 : Time 3425.67s\n",
        "\tTrain | Loss 1.396, Accuracy 0.560\n",
        "\tValid | Loss 1.265, Accuracy 0.614\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-30\n",
        " Epoch 2 : Time 3409.74s\n",
        "\tTrain | Loss 1.391, Accuracy 0.562\n",
        "\tValid | Loss 1.233, Accuracy 0.623\n",
        " Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-31\n",
        " Epoch 3 : Time 3410.26s\n",
        "\tTrain | Loss 1.388, Accuracy 0.563\n",
        "\tValid | Loss 1.250, Accuracy 0.617\n",
        " Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-32\n",
        " Epoch 4 : Time 3410.29s\n",
        "\tTrain | Loss 1.384, Accuracy 0.564\n",
        "\tValid | Loss 1.220, Accuracy 0.628\n",
        " Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-33\n",
        " Epoch 5 : Time 3407.71s\n",
        "\tTrain | Loss 1.381, Accuracy 0.565\n",
        "\tValid | Loss 1.194, Accuracy 0.635\n",
        " Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-34\n",
        " Epoch 6 : Time 3406.20s\n",
        "\tTrain | Loss 1.377, Accuracy 0.566\n",
        "\tValid | Loss 1.188, Accuracy 0.636\n",
        " Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-35\n",
        " Epoch 7 : Time 3409.95s\n",
        "\tTrain | Loss 1.374, Accuracy 0.567\n",
        "\tValid | Loss 1.219, Accuracy 0.630\n",
        " Saving checkpoint for epoch 7 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-36\n",
        " Epoch 8 : Time 3408.65s\n",
        "\tTrain | Loss 1.371, Accuracy 0.568\n",
        "\tValid | Loss 1.258, Accuracy 0.618\n",
        " Saving checkpoint for epoch 8 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-37\n",
        " Epoch 9 : Time 3411.49s\n",
        "\tTrain | Loss 1.368, Accuracy 0.569\n",
        "\tValid | Loss 1.184, Accuracy 0.640\n",
        " Saving checkpoint for epoch 9 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-38\n",
        " Epoch 10 : Time 3406.89s\n",
        "\tTrain | Loss 1.365, Accuracy 0.570\n",
        "\tValid | Loss 1.202, Accuracy 0.637\n",
        " Saving checkpoint for epoch 10 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-39\n",
        " Epoch 11 : Time 3398.39s\n",
        "\tTrain | Loss 1.363, Accuracy 0.571\n",
        "\tValid | Loss 1.235, Accuracy 0.623\n",
        " Saving checkpoint for epoch 11 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-40\n",
        " Epoch 12 : Time 3397.46s\n",
        "\tTrain | Loss 1.359, Accuracy 0.572\n",
        "\tValid | Loss 1.195, Accuracy 0.636\n",
        " Saving checkpoint for epoch 12 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-41\n",
        " Epoch 13 : Time 3405.18s\n",
        "\tTrain | Loss 1.357, Accuracy 0.573\n",
        "\tValid | Loss 1.197, Accuracy 0.636\n",
        " Saving checkpoint for epoch 13 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-42\n",
        " Epoch 14 : Time 3408.87s\n",
        "\tTrain | Loss 1.354, Accuracy 0.574\n",
        "\tValid | Loss 1.196, Accuracy 0.636\n",
        " Saving checkpoint for epoch 14 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-43\n",
        " Epoch 15 : Time 3406.78s\n",
        "\tTrain | Loss 1.352, Accuracy 0.574\n",
        "\tValid | Loss 1.183, Accuracy 0.640\n",
        " Saving checkpoint for epoch 15 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-44\n",
        " Epoch 16 : Time 3407.64s\n",
        "\tTrain | Loss 1.350, Accuracy 0.575\n",
        "\tValid | Loss 1.199, Accuracy 0.634\n",
        " Saving checkpoint for epoch 16 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-45\n",
        " Epoch 17 : Time 3401.42s\n",
        "\tTrain | Loss 1.348, Accuracy 0.576\n",
        "\tValid | Loss 1.179, Accuracy 0.644\n",
        " Saving checkpoint for epoch 17 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-46\n",
        " Epoch 1 : Time 6491.51s\n",
        "\tTrain | Loss 1.345, Accuracy 0.576\n",
        "\tValid | Loss 1.173, Accuracy 0.642\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-47\n",
        "  Epoch 1 : Time 6524.36s\n",
        "\tTrain | Loss 1.344, Accuracy 0.577\n",
        "\tValid | Loss 1.175, Accuracy 0.644\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-48\n",
        "  Epoch 1 : Time 9660.41s\n",
        "\tTrain | Loss 1.342, Accuracy 0.578\n",
        "\tValid | Loss 1.181, Accuracy 0.641\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-49\n",
        " Epoch 1 : Time 6680.26s\n",
        "\tTrain | Loss 1.339, Accuracy 0.578\n",
        "\tValid | Loss 1.198, Accuracy 0.639\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-50\n",
        "  Epoch 1 : Time 9959.75s\n",
        "\tTrain | Loss 1.337, Accuracy 0.579\n",
        "\tValid | Loss 1.186, Accuracy 0.639\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-51\n",
        "\n",
        "'''\n",
        "\n",
        "'''\n",
        "Epoch 1 : Time 3387.09s\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-1\n",
        "\tTrain | Loss 2.443, Accuracy 0.240\n",
        "\tValid | Loss 2.260, Accuracy 0.293\n",
        " Epoch 2 : Time 3382.02s\n",
        " Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-2\n",
        "\tTrain | Loss 2.228, Accuracy 0.305\n",
        "\tValid | Loss 2.091, Accuracy 0.353\n",
        " Epoch 3 : Time 3381.14s\n",
        " Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-3\n",
        "\tTrain | Loss 2.067, Accuracy 0.358\n",
        "\tValid | Loss 1.946, Accuracy 0.401\n",
        " Epoch 4 : Time 3383.31s\n",
        " Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-4\n",
        "\tTrain | Loss 1.941, Accuracy 0.398\n",
        "\tValid | Loss 1.841, Accuracy 0.436\n",
        " Epoch 5 : Time 3379.02s\n",
        " Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-5\n",
        "\tTrain | Loss 1.853, Accuracy 0.425\n",
        "\tValid | Loss 1.772, Accuracy 0.459\n",
        " Epoch 6 : Time 3380.21s\n",
        " Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-6\n",
        "\tTrain | Loss 1.785, Accuracy 0.446\n",
        "\tValid | Loss 1.715, Accuracy 0.477\n",
        " Epoch 7 : Time 3377.84s\n",
        " Saving checkpoint for epoch 7 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-7\n",
        "\tTrain | Loss 1.733, Accuracy 0.462\n",
        "\tValid | Loss 1.666, Accuracy 0.490\n",
        " Epoch 8 : Time 3380.69s\n",
        " Saving checkpoint for epoch 8 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-8\n",
        "\tTrain | Loss 1.692, Accuracy 0.474\n",
        "\tValid | Loss 1.636, Accuracy 0.501\n",
        " Epoch 9 : Time 3383.05s\n",
        " Saving checkpoint for epoch 9 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-9\n",
        "\tTrain | Loss 1.661, Accuracy 0.483\n",
        "\tValid | Loss 1.606, Accuracy 0.510\n",
        " Epoch 10 : Time 3386.42s\n",
        " Saving checkpoint for epoch 10 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-10\n",
        "\tTrain | Loss 1.632, Accuracy 0.492\n",
        "\tValid | Loss 1.592, Accuracy 0.518\n",
        " Epoch 11 : Time 3380.77s\n",
        " Saving checkpoint for epoch 11 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-11\n",
        "\tTrain | Loss 1.610, Accuracy 0.499\n",
        "\tValid | Loss 1.578, Accuracy 0.521\n",
        " Epoch 12 : Time 3383.10s\n",
        " Saving checkpoint for epoch 12 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-12\n",
        "\tTrain | Loss 1.590, Accuracy 0.504\n",
        "\tValid | Loss 1.539, Accuracy 0.530\n",
        " Epoch 13 : Time 3383.12s\n",
        " Saving checkpoint for epoch 13 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-13\n",
        "\tTrain | Loss 1.572, Accuracy 0.510\n",
        "\tValid | Loss 1.525, Accuracy 0.534\n",
        " Epoch 14 : Time 3382.49s\n",
        " Saving checkpoint for epoch 14 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-14\n",
        "\tTrain | Loss 1.557, Accuracy 0.514\n",
        "\tValid | Loss 1.514, Accuracy 0.537\n",
        " Epoch 15 : Time 3383.06s\n",
        " Saving checkpoint for epoch 15 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-15\n",
        "\tTrain | Loss 1.544, Accuracy 0.518\n",
        "\tValid | Loss 1.505, Accuracy 0.539\n",
        " Epoch 16 : Time 3383.69s\n",
        " Saving checkpoint for epoch 16 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-16\n",
        "\tTrain | Loss 1.533, Accuracy 0.521\n",
        "\tValid | Loss 1.504, Accuracy 0.542\n",
        " Epoch 17 : Time 3389.24s\n",
        " Saving checkpoint for epoch 17 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-17\n",
        "\tTrain | Loss 1.522, Accuracy 0.524\n",
        "\tValid | Loss 1.500, Accuracy 0.542\n",
        " Epoch 18 : Time 3391.67s\n",
        " Saving checkpoint for epoch 18 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-18\n",
        "\tTrain | Loss 1.512, Accuracy 0.528\n",
        "\tValid | Loss 1.483, Accuracy 0.547\n",
        " Epoch 19 : Time 3388.94s\n",
        " Saving checkpoint for epoch 19 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-19\n",
        "\tTrain | Loss 1.503, Accuracy 0.530\n",
        "\tValid | Loss 1.467, Accuracy 0.549\n",
        " Epoch 20 : Time 3390.13s\n",
        " Saving checkpoint for epoch 20 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-20\n",
        "\tTrain | Loss 1.495, Accuracy 0.533\n",
        "\tValid | Loss 1.458, Accuracy 0.552\n",
        " Epoch 21 : Time 3384.88s\n",
        " Saving checkpoint for epoch 21 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-21\n",
        "\tTrain | Loss 1.487, Accuracy 0.535\n",
        "\tValid | Loss 1.471, Accuracy 0.552\n",
        " Epoch 22 : Time 3380.05s\n",
        " Saving checkpoint for epoch 22 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-22\n",
        "\tTrain | Loss 1.480, Accuracy 0.537\n",
        "\tValid | Loss 1.458, Accuracy 0.554\n",
        " Epoch 23 : Time 3368.96s\n",
        " Saving checkpoint for epoch 23 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-23\n",
        "\tTrain | Loss 1.473, Accuracy 0.539\n",
        "\tValid | Loss 1.459, Accuracy 0.555\n",
        " Epoch 24 : Time 3374.87s\n",
        " Saving checkpoint for epoch 24 at /content/drive/MyDrive/translateMS/checkpoints/finetuning_128_2_8_512_0.2/ckpt-24\n",
        "\tTrain | Loss 1.467, Accuracy 0.541\n",
        "\tValid | Loss 1.452, Accuracy 0.556\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        " Epoch 1 : Time 6050.81s\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-1\n",
        "\tTrain | Loss 2.026, Accuracy 0.357\n",
        "\tValid | Loss 1.549, Accuracy 0.515\n",
        " Epoch 2 : Time 6051.91s\n",
        " Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-2\n",
        "\tTrain | Loss 1.637, Accuracy 0.483\n",
        "\tValid | Loss 1.354, Accuracy 0.577\n",
        " Epoch 3 : Time 6041.49s\n",
        " Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-3\n",
        "\tTrain | Loss 1.477, Accuracy 0.535\n",
        "\tValid | Loss 1.260, Accuracy 0.613\n",
        " Epoch 4 : Time 5994.15s\n",
        " Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-4\n",
        "\tTrain | Loss 1.380, Accuracy 0.567\n",
        "\tValid | Loss 1.179, Accuracy 0.637\n",
        " Epoch 5 : Time 5911.29s\n",
        " Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-5\n",
        "\tTrain | Loss 1.309, Accuracy 0.589\n",
        "\tValid | Loss 1.138, Accuracy 0.648\n",
        " Epoch 6 : Time 5911.01s\n",
        " Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-6\n",
        "\tTrain | Loss 1.255, Accuracy 0.606\n",
        "\tValid | Loss 1.081, Accuracy 0.667\n",
        " Epoch 7 : Time 5902.05s\n",
        " Saving checkpoint for epoch 7 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-7\n",
        "\tTrain | Loss 1.212, Accuracy 0.620\n",
        "\tValid | Loss 1.085, Accuracy 0.664\n",
        " Epoch 8 : Time 5911.82s\n",
        " Saving checkpoint for epoch 8 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-8\n",
        "\tTrain | Loss 1.177, Accuracy 0.630\n",
        "\tValid | Loss 1.097, Accuracy 0.662\n",
        "  Epoch 1 : Time 6030.05s\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-13\n",
        "\tTrain | Loss 1.146, Accuracy 0.640\n",
        "\tValid | Loss 1.094, Accuracy 0.667\n",
        " Epoch 2 : Time 6000.78s\n",
        " Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-14\n",
        "\tTrain | Loss 1.117, Accuracy 0.650\n",
        "\tValid | Loss 1.009, Accuracy 0.691\n",
        " Epoch 3 : Time 6004.16s\n",
        " Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-15\n",
        "\tTrain | Loss 1.099, Accuracy 0.655\n",
        "\tValid | Loss 0.969, Accuracy 0.702\n",
        " Epoch 4 : Time 6002.66s\n",
        " Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-16\n",
        "\tTrain | Loss 1.085, Accuracy 0.660\n",
        "\tValid | Loss 0.975, Accuracy 0.703\n",
        " Epoch 5 : Time 6002.51s\n",
        " Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-17\n",
        "\tTrain | Loss 1.073, Accuracy 0.663\n",
        "\tValid | Loss 0.918, Accuracy 0.719\n",
        " Epoch 6 : Time 5997.64s\n",
        " Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-18\n",
        "\tTrain | Loss 1.062, Accuracy 0.667\n",
        "\tValid | Loss 0.961, Accuracy 0.706\n",
        " Epoch 7 : Time 5998.73s\n",
        " Saving checkpoint for epoch 7 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-19\n",
        "\tTrain | Loss 1.052, Accuracy 0.670\n",
        "\tValid | Loss 0.948, Accuracy 0.711\n",
        " Epoch 8 : Time 5994.41s\n",
        " Saving checkpoint for epoch 8 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-20\n",
        "\tTrain | Loss 1.044, Accuracy 0.673\n",
        "\tValid | Loss 0.946, Accuracy 0.710\n",
        "  Epoch 9 : Time 5996.41s\n",
        " Saving checkpoint for epoch 9 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-21\n",
        "\tTrain | Loss 1.035, Accuracy 0.675\n",
        "\tValid | Loss 0.898, Accuracy 0.729\n",
        " Epoch 10 : Time 5799.80s\n",
        " Saving checkpoint for epoch 10 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-22\n",
        "\tTrain | Loss 1.028, Accuracy 0.677\n",
        "\tValid | Loss 0.899, Accuracy 0.726\n",
        " Epoch 11 : Time 5789.37s\n",
        " Saving checkpoint for epoch 11 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-23\n",
        "\tTrain | Loss 1.021, Accuracy 0.680\n",
        "\tValid | Loss 0.888, Accuracy 0.729\n",
        " Epoch 12 : Time 5780.74s\n",
        " Saving checkpoint for epoch 12 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-24\n",
        "\tTrain | Loss 1.015, Accuracy 0.682\n",
        "\tValid | Loss 0.865, Accuracy 0.736\n",
        " Epoch 13 : Time 5769.57s\n",
        " Saving checkpoint for epoch 13 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-25\n",
        "\tTrain | Loss 1.009, Accuracy 0.684\n",
        "\tValid | Loss 0.881, Accuracy 0.729\n",
        " Epoch 14 : Time 5814.95s\n",
        " Saving checkpoint for epoch 14 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-26\n",
        "\tTrain | Loss 1.003, Accuracy 0.685\n",
        "\tValid | Loss 0.891, Accuracy 0.730\n",
        "  Epoch 1 : Time 10898.10s\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-27\n",
        "\tTrain | Loss 0.998, Accuracy 0.687\n",
        " \tValid | Loss 0.876, Accuracy 0.733\n",
        " Epoch 2 : Time 10833.03s\n",
        " Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-28\n",
        "\tTrain | Loss 0.993, Accuracy 0.689\n",
        "\tValid | Loss 0.860, Accuracy 0.738\n",
        " Epoch 3 : Time 10826.93s\n",
        " Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-29\n",
        "\tTrain | Loss 0.988, Accuracy 0.690\n",
        "\tValid | Loss 0.849, Accuracy 0.739\n",
        " Epoch 4 : Time 10845.81s\n",
        " Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-30\n",
        "\tTrain | Loss 0.983, Accuracy 0.692\n",
        "\tValid | Loss 0.849, Accuracy 0.742\n",
        " Epoch 5 : Time 10851.41s\n",
        " Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-31\n",
        "\tTrain | Loss 0.979, Accuracy 0.693\n",
        "\tValid | Loss 0.862, Accuracy 0.736\n",
        " Epoch 6 : Time 10857.52s\n",
        " Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-32\n",
        "\tTrain | Loss 0.976, Accuracy 0.694\n",
        "\tValid | Loss 0.875, Accuracy 0.730\n",
        " Epoch 7 : Time 10869.74s\n",
        " Saving checkpoint for epoch 7 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-33\n",
        "\tTrain | Loss 0.972, Accuracy 0.695\n",
        "\tValid | Loss 0.859, Accuracy 0.739\n",
        "   Epoch 1 : Time 5749.89s\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-34\n",
        "\tTrain | Loss 0.968, Accuracy 0.696\n",
        "  Valid | Loss 0.833, Accuracy 0.748\n",
        " Epoch 1 : Time 5728.08s\n",
        " Saving checkpoint for epoch 1 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-36\n",
        "\tTrain | Loss 0.965, Accuracy 0.698\n",
        "\tValid | Loss 0.831, Accuracy 0.749\n",
        " Epoch 2 : Time 5725.86s\n",
        " Saving checkpoint for epoch 2 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-37\n",
        "\tTrain | Loss 0.962, Accuracy 0.699\n",
        "\tValid | Loss 0.876, Accuracy 0.735\n",
        " Epoch 3 : Time 5735.52s\n",
        " Saving checkpoint for epoch 3 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-38\n",
        "\tTrain | Loss 0.958, Accuracy 0.700\n",
        "\tValid | Loss 0.827, Accuracy 0.749\n",
        " Epoch 4 : Time 5721.86s\n",
        " Saving checkpoint for epoch 4 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-39\n",
        "\tTrain | Loss 0.955, Accuracy 0.701\n",
        "\tValid | Loss 0.820, Accuracy 0.751\n",
        " Epoch 5 : Time 5723.23s\n",
        " Saving checkpoint for epoch 5 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-40\n",
        "\tTrain | Loss 0.953, Accuracy 0.702\n",
        "\tValid | Loss 0.853, Accuracy 0.744\n",
        " Epoch 6 : Time 5722.20s\n",
        " Saving checkpoint for epoch 6 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-41\n",
        "\tTrain | Loss 0.950, Accuracy 0.702\n",
        "\tValid | Loss 0.819, Accuracy 0.752\n",
        " Epoch 7 : Time 5732.16s\n",
        " Saving checkpoint for epoch 7 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-42\n",
        "\tTrain | Loss 0.947, Accuracy 0.703\n",
        "\tValid | Loss 0.829, Accuracy 0.749\n",
        " Epoch 8 : Time 5724.54s\n",
        " Saving checkpoint for epoch 8 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-43\n",
        "\tTrain | Loss 0.944, Accuracy 0.704\n",
        "\tValid | Loss 0.831, Accuracy 0.750\n",
        " Epoch 9 : Time 5733.83s\n",
        " Saving checkpoint for epoch 9 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-44\n",
        "\tTrain | Loss 0.942, Accuracy 0.705\n",
        "\tValid | Loss 0.832, Accuracy 0.750\n",
        " Epoch 10 : Time 5723.48s\n",
        " Saving checkpoint for epoch 10 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-45\n",
        "\tTrain | Loss 0.940, Accuracy 0.706\n",
        "\tValid | Loss 0.815, Accuracy 0.756\n",
        " Epoch 11 : Time 5728.75s\n",
        " Saving checkpoint for epoch 11 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-46\n",
        "\tTrain | Loss 0.937, Accuracy 0.707\n",
        "\tValid | Loss 0.800, Accuracy 0.757\n",
        " Epoch 12 : Time 5763.87s\n",
        " Saving checkpoint for epoch 12 at /content/drive/MyDrive/translateMS/checkpoints/finetuning/ckpt-47\n",
        "\tTrain | Loss 0.935, Accuracy 0.707\n",
        "\tValid | Loss 0.812, Accuracy 0.753  \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QmrrwO33hIU"
      },
      "source": [
        "def evaluate_peptide_level(dataset, max_length = 50):\n",
        "    cnt_total =0\n",
        "    cnt_correct = 0\n",
        "    for mz, intensity, sequence in dataset:\n",
        "        cnt_total+=1\n",
        "        if(cnt_total%10 == 0):\n",
        "            print(cnt_total, cnt_correct/(cnt_total-1))\n",
        "\n",
        "        encoder_input = tf.convert_to_tensor([mz])\n",
        "        start, end = 1,2\n",
        "        output = tf.convert_to_tensor([start],dtype=tf.int64)\n",
        "        output = tf.expand_dims(output, 0)\n",
        "\n",
        "        for i in range(max_length):\n",
        "            enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "                encoder_input, output)\n",
        "            # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "            \n",
        "            \n",
        "            encoder1_output, decoder1_output, _, _ = \\\n",
        "                pretrained_transformer(encoder_input,\n",
        "                                      output,\n",
        "                                      False,\n",
        "                                      enc_padding_mask,\n",
        "                                      combined_mask,\n",
        "                                      dec_padding_mask)\n",
        "\n",
        "            predictions, _ = modified_transformer(encoder1_output,\n",
        "                                                  intensity,\n",
        "                                                  decoder1_output,\n",
        "                                                  False,\n",
        "                                                  enc_padding_mask,\n",
        "                                                  combined_mask,\n",
        "                                                  dec_padding_mask)\n",
        "\n",
        "             \n",
        "            # select the last word from the seq_len dimension\n",
        "            predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "            predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "            # concatentate the predicted_id to the output which is given to the decoder\n",
        "            # as its input.\n",
        "            output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "            # return the result if the predicted_id is equal to the end token\n",
        "            if predicted_id == end:\n",
        "                if output.shape[1]==sequence.shape[0] and tf.reduce_all(output[0] == sequence):\n",
        "                    cnt_correct+=1\n",
        "                break\n",
        "\n",
        "    return cnt_correct/cnt_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryyma0b84GhH"
      },
      "source": [
        "test_loss, test_accuracy = evaluate_aminoacid_level_finetuning(real_test_dataset.shuffle(40000).take(5000))\n",
        "print(f'\\ttest | Loss {test_loss:.3f}, Accuracy {test_accuracy:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngkLvFPW_lYe"
      },
      "source": [
        "\n",
        "print(f'\\ttest | Loss {test_loss:.3f}, Accuracy {test_accuracy:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1i6gQHs4Hu9"
      },
      "source": [
        "accuracy_test_data = evaluate_peptide_level(real_test_dataset.shuffle(40000).take(2000))\n",
        "print(f'Accuracy of test data for peptide level : {accuracy_test_data:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}